[
  {
    "objectID": "vignettes/design/Pilot_work.html",
    "href": "vignettes/design/Pilot_work.html",
    "title": "Pilot Work",
    "section": "",
    "text": "Note: This documents contains unstructured notes and code that helped move the project forward at an early stage. At this point our aim was simply to produce an online replication of a design similar to Rogers, Kuiper, and Kirker (1977).\nThe purpose of this vignette is to describe our process for generating stimuli to replicate Experiment 1 from Rogers, Kuiper, and Kirker (1977)."
  },
  {
    "objectID": "vignettes/design/Pilot_work.html#verbatim-method-reprint",
    "href": "vignettes/design/Pilot_work.html#verbatim-method-reprint",
    "title": "Pilot Work",
    "section": "Verbatim method reprint",
    "text": "Verbatim method reprint\nBelow is a verbatim reprint of the original methods. Our goal is to create a conceptually similar list of adjectives.\n“The study has two main parts. First, subjects rated 40 adjectives on one of four tasks. This involved presenting a cue question, followed by 1 of the 40 adjectives. Subjects answered yes or no to the cue question as it applied to the adjective. The cue questions, along with the manipulations for each task, are presented in Table 1. After completing the ratings, subjects attempted to recall the adjectives in the second part of the study.\nMaterials. The main items for this study were 40 adjectives that were deemed appropriate for a self-description task. They were chosen to represent a broad spectrum of possible characteristics and were selected from all of the trait descriptions found in Jackson’s (1967) Personality Research Form A Manual. Thirty-eight of the adjectives, selected to be familiar to the subject population, came from this source. Two other adjectives (shy and outgoing) were added to make up the total of 40.\nWe used Roget’s Thesaurus to construct a further set of 40 synonyms for the semantic tasks. The final synonyms chosen represented consensus among the three authors. The phonemic task dictated a second supplementary list of 40 words that rhymed with the main adjective set. The authors generated a set of possible rhyming words, and consensus among ourselves was the final criterion for selection. Most (90%) of these words were adjectives.\nA third supplementary list of nonsynonym, nonrhyming words was also required, so that one half of the cue questions could result in a no rating. Kirby and Gardner’s (1972) set of adjectives was consulted to derive this list. Again, author consensus regarding the nonrhyming and nonsynonym quality of the adjectives dictated the final list. A set of eight further adjectives and supplementary words was generated to provide buffer items of four ratings each at the beginning and end of the list. These items, which were constant across lists, were not included in the data analysis. This was intended to minimize the effects of primacy and recency in the incidental recall task.\nFour lists of adjectives were constructed, such that 10 adjectives in each list were rated under each cue question, and over the four lists, each adjective was rated under each cue question.\nTo guard against the possibility that wo-rated words are recalled differently than yes-rated words, each of the four lists was reversed to generate eight lists in total. For example, if in a given list, under the structural task, a word appeared in small letters (generating a no response), the reversed list would have the word presented in big letters (generating a yes response). The one exception to this counterbalancing was the self-reference task. Here it was impossible to have experimental control over yes and no responses, since the person’s view of self would dictate his or her response.”"
  },
  {
    "objectID": "vignettes/design/Pilot_work.html#issues",
    "href": "vignettes/design/Pilot_work.html#issues",
    "title": "Pilot Work",
    "section": "Issues",
    "text": "Issues\nThe original study attempted some counterbalancing of words across conditions. Nevertheless, we note the following issues that were not controlled.\n\nThe structural task and the self-reference task involved presentation of a single word, whereas the rhyming and semantic tasks always involved presentation of two words.\n\nWe intend to present two words on each trial, and ask participants to make a yes/no judgment about the first word in relation to the second word. By replacing the phonemic judgment task with a syllable judgment task, we should be able to balance the word pairs across tasks.\nOne goal is that each target word can be presented in any cue-question condition, and recieve a yes or no answer (except for the self-reference questions which is subject-driven)"
  },
  {
    "objectID": "vignettes/design/Pilot_work.html#approach",
    "href": "vignettes/design/Pilot_work.html#approach",
    "title": "Pilot Work",
    "section": "Approach",
    "text": "Approach\nChandler (2018) published updated likeableness and meaningfulness ratings of 555 person-descriptive words. We obtained the list of words that were published in supplementary materials.\nOur plan is to create a table of all unique adjectives with the following structure:\nTarget word Related - Same syllables Unrelated -Same syllables Related - Different syllables Unrelated - Difference syllables\n\nlibrary(rio)\nlibrary(dplyr)\n\nt &lt;- rio::import(\"materials/1-s2.0-S0092656616300848-mmc1.xlsx\")\n\nMeaningful &lt;- t %&gt;%\n  filter(`Replication MTurk Meaningfulness M` &gt; 3)\n\nLow_likable &lt;- Meaningful %&gt;%\n  filter(`Replication MTurk Likability M` &lt; 2) %&gt;%\n  mutate(syllables = nsyllable::nsyllable(Word))\n\nHigh_likable &lt;- Meaningful %&gt;%\n  filter(`Replication MTurk Likability M` &gt; 4 ) %&gt;%\n  mutate(syllables = nsyllable::nsyllable(Word))\n\n\nlow_likeable_list &lt;- list()\n\nfor(i in 236:dim(Low_likable)[1]){\n  \n  current_word &lt;- Low_likable$Word[i]\n  current_word &lt;- gsub(\" \", \"\", current_word)\n  \n  current_syllables &lt;- Low_likable$syllables[i]\n  \n  get_similar &lt;- rhymer::get_means_like(word = current_word, return_type = \"df\", limit = 10)\n  \n  if(!is.null(dim(get_similar))){\n  \n    get_similar &lt;- get_similar %&gt;%\n      mutate(syllables = nsyllable::nsyllable(word))\n    \n    same_syllables &lt;- get_similar %&gt;%\n      filter(syllables == current_syllables)\n    \n    diff_syllables &lt;- get_similar %&gt;%\n      filter(syllables != current_syllables)\n  } else {\n    same_syllables &lt;- NA\n    diff_syllables &lt;- NA\n  }\n  \n  current_list &lt;- list(word = current_word,\n                       syllables = current_syllables,\n                       df_info = Low_likable[i,],\n                       same_syllables = same_syllables,\n                       diff_syllables = diff_syllables\n                       )\n  \n  low_likeable_list[[i]] &lt;- current_list\n  \n}\n\nsave.image(file = \"stimulus.RData\")\n\n\nhigh_likeable_list &lt;- list()\n\nfor(i in 1:dim(High_likable)[1]){\n  \n  current_word &lt;- High_likable$Word[i]\n  current_word &lt;- gsub(\" \", \"\", current_word)\n  \n  current_syllables &lt;- High_likable$syllables[i]\n  \n  get_similar &lt;- rhymer::get_means_like(word = current_word, return_type = \"df\", limit = 10)\n  \n  if(!is.null(dim(get_similar))){\n  \n    get_similar &lt;- get_similar %&gt;%\n      mutate(syllables = nsyllable::nsyllable(word))\n    \n    same_syllables &lt;- get_similar %&gt;%\n      filter(syllables == current_syllables)\n    \n    diff_syllables &lt;- get_similar %&gt;%\n      filter(syllables != current_syllables)\n  } else {\n    same_syllables &lt;- NA\n    diff_syllables &lt;- NA\n  }\n  \n  current_list &lt;- list(word = current_word,\n                       syllables = current_syllables,\n                       df_info = High_likable[i,],\n                       same_syllables = same_syllables,\n                       diff_syllables = diff_syllables\n                       )\n  \n  high_likeable_list[[i]] &lt;- current_list\n  \n}\n\nsave.image(file = \"stimulus.RData\")\n\n\nload(\"stimulus.RData\")\n\nbuild_low_likeable &lt;- data.frame()\n\nfor(i in 1:length(low_likeable_list)){\n  \n  temp_df &lt;- low_likeable_list[[i]]$df_info\n  \n  if(!is.null(dim(low_likeable_list[[i]]$same_syllables))){\n    related_same &lt;- low_likeable_list[[i]]$same_syllables$word[1]\n    related_same_syllables &lt;- low_likeable_list[[i]]$same_syllables$syllables[1]\n  } else {\n    related_same &lt;- NA\n    related_same_syllables &lt;- NA\n  }\n  \n  if(!is.null(dim(low_likeable_list[[i]]$diff_syllables))){\n    related_diff &lt;- low_likeable_list[[i]]$diff_syllables$word[1]\n    related_diff_syllables &lt;- low_likeable_list[[i]]$diff_syllables$syllables[1]\n  } else {\n    related_diff &lt;- NA\n    related_diff_syllables &lt;- NA\n  }\n  \n  temp_df &lt;- temp_df %&gt;%\n    mutate(related_same = related_same,\n           related_same_syllables = related_same_syllables,\n           related_diff = related_diff,\n           related_diff_syllables = related_diff_syllables)\n  \n  build_low_likeable &lt;- rbind(build_low_likeable,temp_df)\n}\n\nbuild_high_likeable &lt;- data.frame()\n\nfor(i in 1:length(high_likeable_list)){\n  \n  temp_df &lt;- high_likeable_list[[i]]$df_info\n  \n  if(!is.null(dim(high_likeable_list[[i]]$same_syllables))){\n    related_same &lt;- high_likeable_list[[i]]$same_syllables$word[1]\n    related_same_syllables &lt;- high_likeable_list[[i]]$same_syllables$syllables[1]\n  } else {\n    related_same &lt;- NA\n    related_same_syllables &lt;- NA\n  }\n  \n  if(!is.null(dim(high_likeable_list[[i]]$diff_syllables))){\n    related_diff &lt;- high_likeable_list[[i]]$diff_syllables$word[1]\n    related_diff_syllables &lt;- high_likeable_list[[i]]$diff_syllables$syllables[1]\n  } else {\n    related_diff &lt;- NA\n    related_diff_syllables &lt;- NA\n  }\n  \n  temp_df &lt;- temp_df %&gt;%\n    mutate(related_same = related_same,\n           related_same_syllables = related_same_syllables,\n           related_diff = related_diff,\n           related_diff_syllables = related_diff_syllables)\n  \n  build_high_likeable &lt;- rbind(build_high_likeable,temp_df)\n}\n\nbuild_low_likeable &lt;- build_low_likeable %&gt;%\n  mutate(likeable_type = \"low\")\n\nbuild_high_likeable &lt;- build_high_likeable %&gt;%\n  mutate(likeable_type = \"high\")\n\nbuild_word_set &lt;- rbind(build_low_likeable,build_high_likeable)\nsave.image(file = \"stimulus.RData\")\n\n\nlibrary(dplyr)\nlibrary(tidyr)\nload(\"stimulus.RData\")\n     \nfiltered_word_set &lt;- build_word_set %&gt;%\n  drop_na(related_same, related_diff) %&gt;%\n  mutate(keep = 1, .before = 1)\n\nrio::export(filtered_word_set,file=\"handpicked.xlsx\")\n\n\nhandpicked &lt;- rio::import(\"handpicked.xlsx\")\n\nhandpicked &lt;- handpicked %&gt;%\n  filter(keep == 1,\n         !grepl(\" \",Word),\n         !grepl(\"-\",Word),\n         !grepl(\" \",related_same),\n         !grepl(\"-\",related_same),\n         !grepl(\" \",related_diff),\n         !grepl(\"-\",related_diff)\n         )\n\nshuffle_id &lt;- sample(1:dim(handpicked)[1])\n\nunique_list &lt;- data.frame()\ni &lt;- 0\nwhile(i &lt; max(dim(handpicked)[1])) {\n  i &lt;- i+1\n  t_df &lt;- handpicked[i,]\n  handpicked &lt;- handpicked %&gt;% \n    filter(Word != t_df$Word,\n           related_same != t_df$Word,\n           related_diff != t_df$Word,\n           Word != t_df$related_same,\n           related_same != t_df$related_same,\n           related_diff != t_df$related_same,\n           Word != t_df$related_diff,\n           related_same != t_df$related_diff,\n           related_diff != t_df$related_diff,\n           )\n  unique_list &lt;- rbind(unique_list,t_df)  \n}\n\nreordered_unique &lt;- unique_list %&gt;%\n  relocate(Word,syllables,\n           related_same,related_same_syllables,\n           related_diff,related_diff_syllables)\n\nrio::export(reordered_unique,file=\"chosen_unique.xlsx\")\n\n\nchosen_unique &lt;- rio::import(\"chosen_unique.xlsx\")\n\nchosen_unique &lt;- chosen_unique %&gt;%\n  filter(Keep == 1) %&gt;%\n  select(Word,syllables,related_same,related_same_syllables,related_diff,related_diff_syllables,likeable_type)\n\nrio::export(chosen_unique,file=\"stimlist.json\")"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html",
    "href": "vignettes/data-analysis/E1_combined.html",
    "title": "E1_combined",
    "section": "",
    "text": "Combination of mturk and sona"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#import-data",
    "href": "vignettes/data-analysis/E1_combined.html#import-data",
    "title": "E1_combined",
    "section": "Import Data",
    "text": "Import Data\n\n# Read the text file from JATOS ...\nread_file('data/E1B_self_reference_deID.JSON') %&gt;%\n  # ... split it into lines ...\n  str_split('\\n') %&gt;% dplyr::first() %&gt;%\n  # ... filter empty rows ...\n  discard(function(x) x == '') %&gt;%\n  # ... parse JSON into a data.frame\n  map_dfr(fromJSON, flatten=T) -&gt; all_data_mturk\n\nread_file('data/E1C_self_reference_deID.JSON') %&gt;%\n  # ... split it into lines ...\n  str_split('\\n') %&gt;% dplyr::first() %&gt;%\n  # ... filter empty rows ...\n  discard(function(x) x == '') %&gt;%\n  # ... parse JSON into a data.frame\n  map_dfr(fromJSON, flatten=T) -&gt; all_data_sona\n\nall_data_sona &lt;- all_data_sona %&gt;%\n  mutate(ID = paste0(ID,\"sona\"))\n\n\nall_data &lt;- rbind(all_data_mturk,all_data_sona)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#demographics",
    "href": "vignettes/data-analysis/E1_combined.html#demographics",
    "title": "E1_combined",
    "section": "Demographics",
    "text": "Demographics\n\nlibrary(tidyr)\n\ndemographics &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-html-form\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response) %&gt;%\n  mutate(age = as.numeric(age))\n\nage_demographics &lt;- demographics %&gt;%\n  summarize(mean_age = mean(age),\n            sd_age = sd(age),\n            min_age = min(age),\n            max_age = max(age))\n\nfactor_demographics &lt;- apply(demographics[-1], 2, table)\n\nA total of 121 participants were recruited from Amazon’s Mechanical Turk. Mean age was NA (range = NA to NA ). There were 78 females, and 39 males. There were 105 right-handed participants, and 12 left or both handed participants. 58 participants reported normal vision, and 53 participants reported corrected-to-normal vision. 94 participants reported English as a first language, and 23 participants reported English as a second language."
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#pre-processing",
    "href": "vignettes/data-analysis/E1_combined.html#pre-processing",
    "title": "E1_combined",
    "section": "Pre-processing",
    "text": "Pre-processing\n50 workers from Amazon’s Mechanical Turk were paid $2.00 to complete this task. The only restriction was to limit workers to the US locale. Typewritten responses during the recall portion indicated that some of the participants were not completing the task as intended. For example, some of the responses appeared to be written by a chatbot, and did not contain words from the experiment.\nWe were were interested in analyzing data from participants who appeared to engage with the task as intended. To identify participants for inclusion we used accuracy data from the case judgment task. We included participants if their accuracy was 70% or greater.\n\nCase judgment accuracy\nGet case judgment accuracy for all participants.\n\ncase_judgment &lt;- all_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         study_instruction == \"case\") %&gt;%\n  mutate(response = as.character(unlist(response))) %&gt;%\n  mutate(accuracy = case_when(\n    response == \"0\" & letter_case == \"upper\" ~ 1,\n    response == \"1\" & letter_case == \"upper\" ~ 0,\n    response == \"0\" & letter_case == \"lower\" ~ 0,\n    response == \"1\" & letter_case == \"lower\" ~ 1\n         )) %&gt;%\n  group_by(ID) %&gt;%\n  summarise(percent_correct = mean(accuracy))\n\nggplot(case_judgment, aes(x=percent_correct))+\n  geom_histogram() +\n  geom_vline(xintercept=.7)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#response-bias",
    "href": "vignettes/data-analysis/E1_combined.html#response-bias",
    "title": "E1_combined",
    "section": "Response bias",
    "text": "Response bias\nCheck to see whether participants pressed one button all of the time. Not used for exclusion.\n\n# get response bias\n\nresponse_bias &lt;-  all_data %&gt;%\n  filter(encoding_trial_type == \"study_word\") %&gt;%\n  mutate(response = as.character(unlist(response))) %&gt;%\n  group_by(ID,study_instruction) %&gt;%\n  count(response)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#post-task-questions",
    "href": "vignettes/data-analysis/E1_combined.html#post-task-questions",
    "title": "E1_combined",
    "section": "post-task questions",
    "text": "post-task questions\n\npost_questions &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-text\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#all-exclusions",
    "href": "vignettes/data-analysis/E1_combined.html#all-exclusions",
    "title": "E1_combined",
    "section": "All exclusions",
    "text": "All exclusions\nno exclusions\n\nall_excluded &lt;- case_judgment %&gt;%\n  filter(percent_correct &lt; .7) %&gt;%\n  select(ID) %&gt;%\n  pull()\n\nlength(all_excluded)\n\n[1] 1\n\nfiltered_data &lt;- all_data %&gt;%\n  filter(ID %in% all_excluded == FALSE)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#define-helper-functions",
    "href": "vignettes/data-analysis/E1_combined.html#define-helper-functions",
    "title": "E1_combined",
    "section": "Define Helper functions",
    "text": "Define Helper functions\nTo do, consider moving the functions into the R package for this project\n\n# attempt general solution\n\n## Declare helper functions\n\n################\n# get_mean_sem\n# data = a data frame\n# grouping_vars = a character vector of factors for analysis contained in data\n# dv = a string indicated the dependent variable colunmn name in data\n# returns data frame with grouping variables, and mean_{dv}, sem_{dv}\n# note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv\n\nget_mean_sem &lt;- function(data, grouping_vars, dv, digits=3){\n  a &lt;- data %&gt;%\n    group_by_at(grouping_vars) %&gt;%\n    summarize(\"mean_{ dv }\" := round(mean(.data[[dv]]), digits),\n              \"sem_{ dv }\" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),\n              .groups=\"drop\")\n  return(a)\n}\n\n################\n# get_effect_names\n# grouping_vars = a character vector of factors for analysis\n# returns a named list\n# list contains all main effects and interaction terms\n# useful for iterating the computation means across design effects and interactions\n\nget_effect_names &lt;- function(grouping_vars){\n  effect_names &lt;- grouping_vars\n  if( length(grouping_vars &gt; 1) ){\n    for( i in 2:length(grouping_vars) ){\n      effect_names &lt;- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=\":\"))\n    }\n  }\n  effects &lt;- strsplit(effect_names, split=\":\")\n  names(effects) &lt;- effect_names\n  return(effects)\n}\n\n################\n# print_list_of_tables\n# table_list = a list of named tables\n# each table is printed \n# names are header level 3\n\nprint_list_of_tables &lt;- function(table_list){\n  for(i in 1:length(table_list)){\n    cat(\"###\",names(table_list[i]))\n    cat(\"\\n\")\n    print(knitr::kable(table_list[[i]]))\n    cat(\"\\n\")\n  }\n}"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#study-phase-immediate-recall",
    "href": "vignettes/data-analysis/E1_combined.html#study-phase-immediate-recall",
    "title": "E1_combined",
    "section": "Study phase immediate recall",
    "text": "Study phase immediate recall\n\n# get recall proportion correct for each participant\nstudy_phase_recall &lt;-  filtered_data %&gt;%\n  filter(phase == \"study_recall\",\n         encoding_recall == \"recall\") %&gt;%\n  separate(col = paragraph,\n           into = c(\"first_word\",\"second_word\"),\n           sep = \" \",\n           remove = FALSE,\n           extra = \"merge\") %&gt;%\n  mutate(accuracy = tolower(target_word) == tolower(first_word),\n         study_instruction = factor(study_instruction, levels= c(\"case\",\"semantic\",\"self\"))) %&gt;%\n  group_by(ID,study_instruction) %&gt;%\n  summarize(percent_correct = mean(accuracy))\n\n# get means in each question condition\nstudy_phase_recall_means &lt;- get_mean_sem(study_phase_recall,\n             grouping_vars = c(\"study_instruction\"),\n             dv = \"percent_correct\")\n\n# run ANOVA\nstudy_phase_recall &lt;- study_phase_recall %&gt;%\n  ungroup() %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction))\n\nstudy_phase_recall_aov &lt;- aov(percent_correct ~ study_instruction + Error(ID/study_instruction),\n    study_phase_recall)\n\n# save printable summaries\nstudy_phase_recall_apa_print &lt;- papaja::apa_print(study_phase_recall_aov)\n\nknitr::kable(study_phase_recall_means)\n\n\n\n\nstudy_instruction\nmean_percent_correct\nsem_percent_correct\n\n\n\n\ncase\n0.873\n0.018\n\n\nsemantic\n0.918\n0.011\n\n\nself\n0.905\n0.015\n\n\n\n\n\nDuring the encoding phase participants attempted to immediately recall half of the words following the primary judgment. We computed proportion of correctly recalled words for each participant separately in each encoding question condition. These means were submitted to a one-way repeated measures ANOVA, with question type as the sole factor. Mean proportion correctly recalled was 0.873 in the case judgment, 0.918 in the semantic judgment, and 0.905 in the self-reference condition; \\(F(2, 234) = 4.03\\), \\(\\mathit{MSE} = 0.02\\), \\(p = .019\\), \\(\\hat{\\eta}^2_G = .014\\)."
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#study-phase-word-judgment",
    "href": "vignettes/data-analysis/E1_combined.html#study-phase-word-judgment",
    "title": "E1_combined",
    "section": "Study phase word judgment",
    "text": "Study phase word judgment\n\n# get recall proportion correct for each participant\nstudy_phase_judgment &lt;-  filtered_data %&gt;%\n  \n  filter(phase == \"main_study\",\n         encoding_trial_type == \"study_word\")  %&gt;%\n  \n  mutate(accuracy = case_when(study_instruction == \"case\" & \n                                letter_case == \"lower\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"case\" & \n                                letter_case == \"lower\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"case\" & \n                                letter_case == \"upper\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"case\" & \n                                letter_case == \"upper\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"low\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"low\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"high\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"high\" &\n                                response == 1 ~ FALSE,\n                              study_instruction == \"self\" & \n                                likeable == \"low\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"self\" & \n                                likeable == \"low\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"self\" & \n                                likeable == \"high\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"self\" & \n                                likeable == \"high\" &\n                                response == 1 ~ FALSE\n                              ),\n         study_instruction = factor(study_instruction, \n                                    levels= c(\"case\",\"semantic\",\"self\"))) %&gt;%\n  \n  group_by(ID,study_instruction) %&gt;%\n  \n  summarize(percent_correct = mean(accuracy)) %&gt;%\n  ungroup()\n\n# get means in each question condition\nstudy_phase_judgment_means &lt;- get_mean_sem(study_phase_judgment,\n             grouping_vars = c(\"study_instruction\"),\n             dv = \"percent_correct\")\n\nknitr::kable(study_phase_judgment_means)\n\n\n\n\nstudy_instruction\nmean_percent_correct\nsem_percent_correct\n\n\n\n\ncase\n0.999\n0.001\n\n\nsemantic\n0.961\n0.006\n\n\nself\n0.782\n0.015\n\n\n\n\n\nFor completeness we report mean performance in the encoding phase for each of the word judgment condition. See above table."
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#recall-test",
    "href": "vignettes/data-analysis/E1_combined.html#recall-test",
    "title": "E1_combined",
    "section": "Recall Test",
    "text": "Recall Test\n\n# obtain recall data from typed answers\n\nrecall_data &lt;- filtered_data %&gt;%\n  filter(phase %in% c(\"recall_1\",\"recall_2\") == TRUE ) %&gt;%\n  select(ID,phase,paragraph) %&gt;%\n  pivot_wider(names_from = phase,\n              values_from = paragraph) %&gt;%\n  mutate(recall_1 = unlist(lapply(recall_1,\"[[\",1)),\n         recall_2 = unlist(lapply(recall_2,\"[[\",1))) %&gt;%\n  mutate(recall_1 = paste(recall_1,recall_2,sep = \" \")) %&gt;%\n  select(ID,recall_1) %&gt;%\n # separate_longer_delim(cols = recall_1,\n #                        delim = \" \") %&gt;%\n  mutate(recall_1 = tolower(recall_1)) %&gt;%\n  mutate(recall_1 = gsub(\"[^[:alnum:][:space:]]\",\"\",recall_1))\n\nencoding_words_per_subject &lt;- filtered_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         phase == \"main_study\")\n\nrecall_data &lt;- left_join(encoding_words_per_subject,recall_data,by = 'ID') %&gt;%\n  mutate(recall_1 = strsplit(recall_1,\" \"))\n\n# implement a spell-checking method\n\nrecall_success &lt;- c()\nmin_string_distance &lt;- c()\nfor(i in 1:dim(recall_data)[1]){\n  recalled_words &lt;- unlist(recall_data$recall_1[i])\n  recalled_words &lt;- recalled_words[recalled_words != \"\"]\n  if (length(recalled_words) == 0 ) recalled_words &lt;- \"nonerecalled\"\n  recall_success[i] &lt;- tolower(recall_data$target_word[i]) %in% recalled_words\n  min_string_distance[i] &lt;- min(sapply(recalled_words,FUN = function(x) {\n  stringdist::stringdist(a=x,b = tolower(recall_data$target_word[i]), method = \"lv\")\n}))\n}\n\n# recall proportion correct by subject\n# correct for unequal conditions. 4 words in recall, 8 words in no recall\n\nrecall_data_subject &lt;- recall_data %&gt;%\n  mutate(recall_success = recall_success,\n         min_string_distance = min_string_distance) %&gt;%\n  mutate(close_recall = min_string_distance &lt;= 2) %&gt;%\n  group_by(ID,study_instruction,encoding_recall,block_type) %&gt;%\n  summarise(number_recalled = sum(recall_success),\n            number_close_recalled = sum(close_recall)) %&gt;%\n  ungroup() %&gt;%\n  mutate(proportion_recalled = case_when(encoding_recall == \"no_recall\" ~ number_close_recalled/6,\n                                         encoding_recall == \"recall\" ~ number_close_recalled/6)) %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction),\n         encoding_recall = as.factor(encoding_recall),\n         block_type = as.factor(block_type))\n\n# Condition means\nmean_recall_data &lt;- get_mean_sem(recall_data_subject,\n             c(\"study_instruction\",\"encoding_recall\", \"block_type\"),\n             \"proportion_recalled\") %&gt;%\n  ungroup() %&gt;%\n  mutate(study_instruction = factor(study_instruction,levels = c(\"case\",\"semantic\",\"self\")),\n         `Retrieval Practice` = case_when(\n           encoding_recall == \"no_recall\" ~ \"No Retrieval Practice \\n during study \\n\",\n           encoding_recall == \"recall\" ~ \"Retrieval Practice \\n during study \\n\",\n                                          ))\n\nrecall_plot &lt;- ggplot(mean_recall_data,\n       aes(x = study_instruction,\n           y = mean_proportion_recalled,\n           fill= `Retrieval Practice`))+\n  geom_bar(stat=\"identity\",position=\"dodge\",color=\"black\") +\n  geom_errorbar(aes(ymin = mean_proportion_recalled - sem_proportion_recalled,\n                    ymax = mean_proportion_recalled + sem_proportion_recalled),\n                width=.9, position=position_dodge2(width = 0.2, padding = 0.8)) +\n  ylab(\"Proportion words recalled\")+\n  xlab(\"Study Instruction\") +\n  theme_classic(base_size = 15)+\n  theme(legend.position = \"top\")+\n  facet_wrap(~block_type)\n\nrecall_plot"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#recall-test-anova",
    "href": "vignettes/data-analysis/E1_combined.html#recall-test-anova",
    "title": "E1_combined",
    "section": "Recall test ANOVA",
    "text": "Recall test ANOVA\n\n## Condition-level means\n# get all possible main effects and interactions\nrecall_effect_names &lt;- get_effect_names(c(\"block_type\",\"encoding_recall\", \"study_instruction\"))\n\nrecall_effect_means &lt;- lapply(recall_effect_names, FUN = function(x) {\n  get_mean_sem(data=recall_data_subject,\n               grouping_vars = x,\n               dv = \"proportion_recalled\") %&gt;%\n    as.data.table()\n})\n\n\n\n# run ANOVA\nrecall_aov &lt;- aov(proportion_recalled ~ block_type*encoding_recall*study_instruction + Error(ID/(study_instruction*encoding_recall)), data = recall_data_subject)\n\n# save printable summaries\nrecall_apa_print &lt;- papaja::apa_print(recall_aov)\n\nknitr::kable(xtable(summary(recall_aov)))\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nblock_type\n1\n0.1618656\n0.1618656\n1.3525608\n0.2472178\n\n\nResiduals\n116\n13.8821159\n0.1196734\nNA\nNA\n\n\nstudy_instruction\n2\n1.7205744\n0.8602872\n23.2130614\n0.0000000\n\n\nblock_type:study_instruction\n2\n0.0610239\n0.0305120\n0.8233016\n0.4402583\n\n\nResiduals\n232\n8.5980313\n0.0370605\nNA\nNA\n\n\nencoding_recall\n1\n0.6528955\n0.6528955\n26.2258962\n0.0000012\n\n\nblock_type:encoding_recall\n1\n0.0102025\n0.0102025\n0.4098207\n0.5233230\n\n\nResiduals\n116\n2.8878279\n0.0248951\nNA\nNA\n\n\nencoding_recall:study_instruction\n2\n0.1207627\n0.0603814\n2.5906930\n0.0771359\n\n\nblock_type:encoding_recall:study_instruction\n2\n0.0738586\n0.0369293\n1.5844697\n0.2072673\n\n\nResiduals\n232\n5.4072306\n0.0233070\nNA\nNA"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#collapse-over-blocking-variable",
    "href": "vignettes/data-analysis/E1_combined.html#collapse-over-blocking-variable",
    "title": "E1_combined",
    "section": "Collapse over blocking variable",
    "text": "Collapse over blocking variable\n\nmean_recall_data_collapsed &lt;- get_mean_sem(recall_data_subject,\n             c(\"study_instruction\",\"encoding_recall\"),\n             \"proportion_recalled\") %&gt;%\n  ungroup() %&gt;%\n  mutate(study_instruction = factor(study_instruction,levels = c(\"case\",\"semantic\",\"self\")),\n         `Retrieval Practice` = case_when(\n           encoding_recall == \"no_recall\" ~ \"No Retrieval Practice \\n during study \\n\",\n           encoding_recall == \"recall\" ~ \"Retrieval Practice \\n during study \\n\",\n                                          ))\n\nrecall_plot_collapsed &lt;- ggplot(mean_recall_data_collapsed,\n       aes(x = study_instruction,\n           y = mean_proportion_recalled,\n           fill= `Retrieval Practice`))+\n  geom_bar(stat=\"identity\",position=\"dodge\",color=\"black\") +\n  geom_errorbar(aes(ymin = mean_proportion_recalled - sem_proportion_recalled,\n                    ymax = mean_proportion_recalled + sem_proportion_recalled),\n                width=.9, position=position_dodge2(width = 0.2, padding = 0.8)) +\n  ylab(\"Proportion words recalled\")+\n  xlab(\"Study Instruction\") +\n  theme_classic(base_size = 15)+\n  theme(legend.position = \"top\")\n\nrecall_plot_collapsed\n\n\n\n\n\n\n\n\n\n## Condition-level means\n# get all possible main effects and interactions\nrecall_effect_names_collapsed &lt;- get_effect_names(c(\"encoding_recall\", \"study_instruction\"))\n\nrecall_effect_means_collapsed &lt;- lapply(recall_effect_names_collapsed, FUN = function(x) {\n  get_mean_sem(data=recall_data_subject,\n               grouping_vars = x,\n               dv = \"proportion_recalled\") %&gt;%\n    as.data.table()\n})\n\n\n\n# run ANOVA\nrecall_aov_collapsed &lt;- aov(proportion_recalled ~ encoding_recall*study_instruction + Error(ID/(study_instruction*encoding_recall)), data = recall_data_subject)\n\n# save printable summaries\nrecall_apa_print_collapsed &lt;- papaja::apa_print(recall_aov_collapsed)\n\nknitr::kable(xtable(summary(recall_aov_collapsed)))\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nResiduals\n117\n14.0439815\n0.1200340\nNA\nNA\n\n\nstudy_instruction\n2\n1.7205744\n0.8602872\n23.248172\n0.0000000\n\n\nResiduals\n234\n8.6590552\n0.0370045\nNA\nNA\n\n\nencoding_recall\n1\n0.6528955\n0.6528955\n26.358857\n0.0000011\n\n\nResiduals\n117\n2.8980304\n0.0247695\nNA\nNA\n\n\nencoding_recall:study_instruction\n2\n0.1207627\n0.0603814\n2.577816\n0.0780951\n\n\nResiduals\n234\n5.4810891\n0.0234235\nNA\nNA"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#simple-effects",
    "href": "vignettes/data-analysis/E1_combined.html#simple-effects",
    "title": "E1_combined",
    "section": "simple effects",
    "text": "simple effects\nCompare retrieval practice vs no retrieval practice for each judgment condition\n\n# Self condition\n# Retrieval practice vs no retrieval practice\nself_retrieval_practice &lt;- recall_data_subject %&gt;%\n  filter(study_instruction == \"self\")\n\nself_retrieval_practice_t &lt;- t.test(proportion_recalled ~ encoding_recall, paired = TRUE, data= self_retrieval_practice)\n\nself_retrieval_practice_t_apa &lt;- papaja::apa_print(self_retrieval_practice_t)\n\n# Semantic condition\n# Retrieval practice vs no retrieval practice\nsemantic_retrieval_practice &lt;- recall_data_subject %&gt;%\n  filter(study_instruction == \"semantic\")\n\nsemantic_retrieval_practice_t &lt;- t.test(proportion_recalled ~ encoding_recall, paired = TRUE, data= semantic_retrieval_practice)\n\nsemantic_retrieval_practice_t_apa &lt;- papaja::apa_print(semantic_retrieval_practice_t)\n\n# Case condition\n# Retrieval practice vs no retrieval practice\n\ncase_retrieval_practice &lt;- recall_data_subject %&gt;%\n  filter(study_instruction == \"case\")\n\ncase_retrieval_practice_t &lt;- t.test(proportion_recalled ~ encoding_recall, paired = TRUE, data= case_retrieval_practice)\n\ncase_retrieval_practice_t_apa &lt;- papaja::apa_print(case_retrieval_practice_t)\n\nCompare self-reference vs. semantic separately for retrieval and no-retrieval conditions.\n\n# self reference effect in no retrieval practice condition\nself_semantic_no_retrieval &lt;- recall_data_subject %&gt;%\n  filter(study_instruction %in% c(\"self\",\"semantic\") == TRUE,\n         encoding_recall == \"no_recall\")\n\nself_semantic_no_retrieval_t &lt;- t.test(proportion_recalled ~ study_instruction, paired = TRUE, data= self_semantic_no_retrieval)\n\nself_semantic_no_retrieval_t_apa &lt;- papaja::apa_print(self_semantic_no_retrieval_t)\n\n\n# self reference effect in retrieval practice condition\nself_semantic_retrieval &lt;- recall_data_subject %&gt;%\n  filter(study_instruction %in% c(\"self\",\"semantic\") == TRUE,\n         encoding_recall == \"recall\")\n\nself_semantic_retrieval_t &lt;- t.test(proportion_recalled ~ study_instruction, paired = TRUE, data= self_semantic_retrieval)\n\nself_semantic_retrieval_t_apa &lt;- papaja::apa_print(self_semantic_retrieval_t)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#write-up",
    "href": "vignettes/data-analysis/E1_combined.html#write-up",
    "title": "E1_combined",
    "section": "Write-up",
    "text": "Write-up\n\n# use data.table \n\n#t &lt;- as.data.table(Accuracy$means$`encoding_stimulus_time:encoding_instruction`)\n#t[encoding_stimulus_time==500 & encoding_instruction == \"F\"]$mean_correct"
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#results",
    "href": "vignettes/data-analysis/E1_combined.html#results",
    "title": "E1_combined",
    "section": "Results",
    "text": "Results\nThere was a main effect of encoding question, \\(F(2, 234) = 23.25\\), \\(\\mathit{MSE} = 0.04\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .052\\). Mean proportion recall was lowest in the case condition (M = 0.143, SEM = 0.012), higher for the semantic condition (M = 0.219, SEM = 0.014), and highest for the self condition (M = 0.263, SEM = 0.015).\nThe retrieval practice effect was also significant, \\(F(1, 117) = 26.36\\), \\(\\mathit{MSE} = 0.02\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .021\\). Mean proportion recall was lower for items that did not receive retrieval practice (M = 0.178, SEM = 0.011), compared to items that did receive retrieval practice (M = 0.239, SEM = 0.012).\nThe interaction between retrieval practice and encoding question approached significance, \\(F(2, 234) = 2.58\\), \\(\\mathit{MSE} = 0.02\\), \\(p = .078\\), \\(\\hat{\\eta}^2_G = .004\\)."
  },
  {
    "objectID": "vignettes/data-analysis/E1_combined.html#save-data",
    "href": "vignettes/data-analysis/E1_combined.html#save-data",
    "title": "E1_combined",
    "section": "save data",
    "text": "save data\n\nsave.image(\"data/E1_combined.RData\")"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html",
    "href": "vignettes/data-analysis/E1_C_analysis.html",
    "title": "Experiment 1C: SONA participants",
    "section": "",
    "text": "Data collected 10/19/23 Brooklyn College SONA participants\nMasters, US, 95% hit approval, more than 200 hits"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#import-data",
    "href": "vignettes/data-analysis/E1_C_analysis.html#import-data",
    "title": "Experiment 1C: SONA participants",
    "section": "Import Data",
    "text": "Import Data\n\n# Read the text file from JATOS ...\nread_file('data/E1C_self_reference_deID.JSON') %&gt;%\n  # ... split it into lines ...\n  str_split('\\n') %&gt;% first() %&gt;%\n  # ... filter empty rows ...\n  discard(function(x) x == '') %&gt;%\n  # ... parse JSON into a data.frame\n  map_dfr(fromJSON, flatten=T) -&gt; all_data"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#demographics",
    "href": "vignettes/data-analysis/E1_C_analysis.html#demographics",
    "title": "Experiment 1C: SONA participants",
    "section": "Demographics",
    "text": "Demographics\n\nlibrary(tidyr)\n\ndemographics &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-html-form\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response) %&gt;%\n  mutate(age = as.numeric(age)) %&gt;%\n  filter(is.na(age) == FALSE)\n\nage_demographics &lt;- demographics %&gt;%\n  summarize(mean_age = mean(age),\n            sd_age = sd(age),\n            min_age = min(age),\n            max_age = max(age))\n\nfactor_demographics &lt;- apply(demographics[-1], 2, table)\n\nA total of 65 participants were recruited from Amazon’s Mechanical Turk. Mean age was 21.6 (range = 18 to 49 ). There were 48 females, and 16 males. There were 56 right-handed participants, and 8 left or both handed participants. 30 participants reported normal vision, and 28 participants reported corrected-to-normal vision. 42 participants reported English as a first language, and 22 participants reported English as a second language."
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#pre-processing",
    "href": "vignettes/data-analysis/E1_C_analysis.html#pre-processing",
    "title": "Experiment 1C: SONA participants",
    "section": "Pre-processing",
    "text": "Pre-processing\n50 workers from Amazon’s Mechanical Turk were paid $2.00 to complete this task. The only restriction was to limit workers to the US locale. Typewritten responses during the recall portion indicated that some of the participants were not completing the task as intended. For example, some of the responses appeared to be written by a chatbot, and did not contain words from the experiment.\nWe were were interested in analyzing data from participants who appeared to engage with the task as intended. To identify participants for inclusion we used accuracy data from the case judgment task. We included participants if their accuracy was 70% or greater.\n\nCase judgment accuracy\nGet case judgment accuracy for all participants.\n\ncase_judgment &lt;- all_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         study_instruction == \"case\") %&gt;%\n  mutate(response = as.character(unlist(response))) %&gt;%\n  mutate(accuracy = case_when(\n    response == \"0\" & letter_case == \"upper\" ~ 1,\n    response == \"1\" & letter_case == \"upper\" ~ 0,\n    response == \"0\" & letter_case == \"lower\" ~ 0,\n    response == \"1\" & letter_case == \"lower\" ~ 1\n         )) %&gt;%\n  group_by(ID) %&gt;%\n  summarise(percent_correct = mean(accuracy))\n\nggplot(case_judgment, aes(x=percent_correct))+\n  geom_histogram() +\n  geom_vline(xintercept=.7)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#response-bias",
    "href": "vignettes/data-analysis/E1_C_analysis.html#response-bias",
    "title": "Experiment 1C: SONA participants",
    "section": "Response bias",
    "text": "Response bias\nCheck to see whether participants pressed one button all of the time. Not used for exclusion.\n\n# get response bias\n\nresponse_bias &lt;-  all_data %&gt;%\n  filter(encoding_trial_type == \"study_word\") %&gt;%\n  mutate(response = as.character(unlist(response))) %&gt;%\n  group_by(ID,study_instruction) %&gt;%\n  count(response)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#post-task-questions",
    "href": "vignettes/data-analysis/E1_C_analysis.html#post-task-questions",
    "title": "Experiment 1C: SONA participants",
    "section": "post-task questions",
    "text": "post-task questions\n\npost_questions &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-text\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#all-exclusions",
    "href": "vignettes/data-analysis/E1_C_analysis.html#all-exclusions",
    "title": "Experiment 1C: SONA participants",
    "section": "All exclusions",
    "text": "All exclusions\nno exclusions\n\nall_excluded &lt;- case_judgment %&gt;%\n  filter(percent_correct &lt; .7) %&gt;%\n  select(ID) %&gt;%\n  pull()\n\nlength(all_excluded)\n\n[1] 1\n\nfiltered_data &lt;- all_data %&gt;%\n  filter(ID %in% all_excluded == FALSE)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#define-helper-functions",
    "href": "vignettes/data-analysis/E1_C_analysis.html#define-helper-functions",
    "title": "Experiment 1C: SONA participants",
    "section": "Define Helper functions",
    "text": "Define Helper functions\nTo do, consider moving the functions into the R package for this project\n\n# attempt general solution\n\n## Declare helper functions\n\n################\n# get_mean_sem\n# data = a data frame\n# grouping_vars = a character vector of factors for analysis contained in data\n# dv = a string indicated the dependent variable colunmn name in data\n# returns data frame with grouping variables, and mean_{dv}, sem_{dv}\n# note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv\n\nget_mean_sem &lt;- function(data, grouping_vars, dv, digits=3){\n  a &lt;- data %&gt;%\n    group_by_at(grouping_vars) %&gt;%\n    summarize(\"mean_{ dv }\" := round(mean(.data[[dv]]), digits),\n              \"sem_{ dv }\" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),\n              .groups=\"drop\")\n  return(a)\n}\n\n################\n# get_effect_names\n# grouping_vars = a character vector of factors for analysis\n# returns a named list\n# list contains all main effects and interaction terms\n# useful for iterating the computation means across design effects and interactions\n\nget_effect_names &lt;- function(grouping_vars){\n  effect_names &lt;- grouping_vars\n  if( length(grouping_vars &gt; 1) ){\n    for( i in 2:length(grouping_vars) ){\n      effect_names &lt;- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=\":\"))\n    }\n  }\n  effects &lt;- strsplit(effect_names, split=\":\")\n  names(effects) &lt;- effect_names\n  return(effects)\n}\n\n################\n# print_list_of_tables\n# table_list = a list of named tables\n# each table is printed \n# names are header level 3\n\nprint_list_of_tables &lt;- function(table_list){\n  for(i in 1:length(table_list)){\n    cat(\"###\",names(table_list[i]))\n    cat(\"\\n\")\n    print(knitr::kable(table_list[[i]]))\n    cat(\"\\n\")\n  }\n}"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#study-phase-immediate-recall",
    "href": "vignettes/data-analysis/E1_C_analysis.html#study-phase-immediate-recall",
    "title": "Experiment 1C: SONA participants",
    "section": "Study phase immediate recall",
    "text": "Study phase immediate recall\n\n# get recall proportion correct for each participant\nstudy_phase_recall &lt;-  filtered_data %&gt;%\n  filter(phase == \"study_recall\",\n         encoding_recall == \"recall\") %&gt;%\n  separate(col = paragraph,\n           into = c(\"first_word\",\"second_word\"),\n           sep = \" \",\n           remove = FALSE,\n           extra = \"merge\") %&gt;%\n  mutate(accuracy = tolower(target_word) == tolower(first_word),\n         study_instruction = factor(study_instruction, levels= c(\"case\",\"semantic\",\"self\"))) %&gt;%\n  group_by(ID,study_instruction) %&gt;%\n  summarize(percent_correct = mean(accuracy))\n\n# get means in each question condition\nstudy_phase_recall_means &lt;- get_mean_sem(study_phase_recall,\n             grouping_vars = c(\"study_instruction\"),\n             dv = \"percent_correct\")\n\n# run ANOVA\nstudy_phase_recall &lt;- study_phase_recall %&gt;%\n  ungroup() %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction))\n\nstudy_phase_recall_aov &lt;- aov(percent_correct ~ study_instruction + Error(ID/study_instruction),\n    study_phase_recall)\n\n# save printable summaries\nstudy_phase_recall_apa_print &lt;- papaja::apa_print(study_phase_recall_aov)\n\nknitr::kable(study_phase_recall_means)\n\n\n\n\nstudy_instruction\nmean_percent_correct\nsem_percent_correct\n\n\n\n\ncase\n0.849\n0.026\n\n\nsemantic\n0.892\n0.017\n\n\nself\n0.872\n0.023\n\n\n\n\n\nDuring the encoding phase participants attempted to immediately recall half of the words following the primary judgment. We computed proportion of correctly recalled words for each participant separately in each encoding question condition. These means were submitted to a one-way repeated measures ANOVA, with question type as the sole factor. Mean proportion correctly recalled was 0.849 in the case judgment, 0.892 in the semantic judgment, and 0.872 in the self-reference condition; \\(F(2, 128) = 1.50\\), \\(\\mathit{MSE} = 0.02\\), \\(p = .228\\), \\(\\hat{\\eta}^2_G = .010\\)."
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#study-phase-word-judgment",
    "href": "vignettes/data-analysis/E1_C_analysis.html#study-phase-word-judgment",
    "title": "Experiment 1C: SONA participants",
    "section": "Study phase word judgment",
    "text": "Study phase word judgment\n\n# get recall proportion correct for each participant\nstudy_phase_judgment &lt;-  filtered_data %&gt;%\n  \n  filter(phase == \"main_study\",\n         encoding_trial_type == \"study_word\")  %&gt;%\n  \n  mutate(accuracy = case_when(study_instruction == \"case\" & \n                                letter_case == \"lower\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"case\" & \n                                letter_case == \"lower\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"case\" & \n                                letter_case == \"upper\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"case\" & \n                                letter_case == \"upper\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"low\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"low\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"high\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"high\" &\n                                response == 1 ~ FALSE,\n                              study_instruction == \"self\" & \n                                likeable == \"low\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"self\" & \n                                likeable == \"low\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"self\" & \n                                likeable == \"high\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"self\" & \n                                likeable == \"high\" &\n                                response == 1 ~ FALSE\n                              ),\n         study_instruction = factor(study_instruction, \n                                    levels= c(\"case\",\"semantic\",\"self\"))) %&gt;%\n  \n  group_by(ID,study_instruction) %&gt;%\n  \n  summarize(percent_correct = mean(accuracy)) %&gt;%\n  ungroup()\n\n# get means in each question condition\nstudy_phase_judgment_means &lt;- get_mean_sem(study_phase_judgment,\n             grouping_vars = c(\"study_instruction\"),\n             dv = \"percent_correct\")\n\nknitr::kable(study_phase_judgment_means)\n\n\n\n\nstudy_instruction\nmean_percent_correct\nsem_percent_correct\n\n\n\n\ncase\n0.999\n0.001\n\n\nsemantic\n0.951\n0.009\n\n\nself\n0.783\n0.018\n\n\n\n\n\nFor completeness we report mean performance in the encoding phase for each of the word judgment condition. See above table."
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#recall-test",
    "href": "vignettes/data-analysis/E1_C_analysis.html#recall-test",
    "title": "Experiment 1C: SONA participants",
    "section": "Recall Test",
    "text": "Recall Test\n\n# obtain recall data from typed answers\n\nrecall_data &lt;- filtered_data %&gt;%\n  filter(phase %in% c(\"recall_1\",\"recall_2\") == TRUE ) %&gt;%\n  select(ID,phase,paragraph) %&gt;%\n  pivot_wider(names_from = phase,\n              values_from = paragraph) %&gt;%\n  mutate(recall_1 = paste(recall_1,recall_2,sep = \" \")) %&gt;%\n  select(ID,recall_1) %&gt;%\n # separate_longer_delim(cols = recall_1,\n #                        delim = \" \") %&gt;%\n  mutate(recall_1 = tolower(recall_1)) %&gt;%\n  mutate(recall_1 = gsub(\"[^[:alnum:][:space:]]\",\"\",recall_1))\n\nencoding_words_per_subject &lt;- filtered_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         phase == \"main_study\")\n\nrecall_data &lt;- left_join(encoding_words_per_subject,recall_data,by = 'ID') %&gt;%\n  mutate(recall_1 = strsplit(recall_1,\" \"))\n\n# implement a spell-checking method\n\nrecall_success &lt;- c()\nmin_string_distance &lt;- c()\nfor(i in 1:dim(recall_data)[1]){\n  recalled_words &lt;- unlist(recall_data$recall_1[i])\n  recalled_words &lt;- recalled_words[recalled_words != \"\"]\n  if (length(recalled_words) == 0 ) recalled_words &lt;- \"nonerecalled\"\n  recall_success[i] &lt;- tolower(recall_data$target_word[i]) %in% recalled_words\n  min_string_distance[i] &lt;- min(sapply(recalled_words,FUN = function(x) {\n  stringdist::stringdist(a=x,b = tolower(recall_data$target_word[i]), method = \"lv\")\n}))\n}\n\n# recall proportion correct by subject\n# correct for unequal conditions. 4 words in recall, 8 words in no recall\n\nrecall_data_subject &lt;- recall_data %&gt;%\n  mutate(recall_success = recall_success,\n         min_string_distance = min_string_distance) %&gt;%\n  mutate(close_recall = min_string_distance &lt;= 2) %&gt;%\n  group_by(ID,study_instruction,encoding_recall,block_type) %&gt;%\n  summarise(number_recalled = sum(recall_success),\n            number_close_recalled = sum(close_recall)) %&gt;%\n  ungroup() %&gt;%\n  mutate(proportion_recalled = case_when(encoding_recall == \"no_recall\" ~ number_close_recalled/6,\n                                         encoding_recall == \"recall\" ~ number_close_recalled/6)) %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction),\n         encoding_recall = as.factor(encoding_recall),\n         block_type = as.factor(block_type))\n\n# Condition means\nmean_recall_data &lt;- get_mean_sem(recall_data_subject,\n             c(\"study_instruction\",\"encoding_recall\", \"block_type\"),\n             \"proportion_recalled\") %&gt;%\n  ungroup() %&gt;%\n  mutate(study_instruction = factor(study_instruction,levels = c(\"case\",\"semantic\",\"self\")),\n         `Retrieval Practice` = case_when(\n           encoding_recall == \"no_recall\" ~ \"No Retrieval Practice \\n during study \\n\",\n           encoding_recall == \"recall\" ~ \"Retrieval Practice \\n during study \\n\",\n                                          ))\n\nrecall_plot &lt;- ggplot(mean_recall_data,\n       aes(x = study_instruction,\n           y = mean_proportion_recalled,\n           fill= `Retrieval Practice`))+\n  geom_bar(stat=\"identity\",position=\"dodge\",color=\"black\") +\n  geom_errorbar(aes(ymin = mean_proportion_recalled - sem_proportion_recalled,\n                    ymax = mean_proportion_recalled + sem_proportion_recalled),\n                width=.9, position=position_dodge2(width = 0.2, padding = 0.8)) +\n  ylab(\"Proportion words recalled\")+\n  xlab(\"Study Instruction\") +\n  theme_classic(base_size = 15)+\n  theme(legend.position = \"top\")+\n  facet_wrap(~block_type)\n\nrecall_plot"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#recall-test-anova",
    "href": "vignettes/data-analysis/E1_C_analysis.html#recall-test-anova",
    "title": "Experiment 1C: SONA participants",
    "section": "Recall test ANOVA",
    "text": "Recall test ANOVA\n\n## Condition-level means\n# get all possible main effects and interactions\nrecall_effect_names &lt;- get_effect_names(c(\"block_type\",\"encoding_recall\", \"study_instruction\"))\n\nrecall_effect_means &lt;- lapply(recall_effect_names, FUN = function(x) {\n  get_mean_sem(data=recall_data_subject,\n               grouping_vars = x,\n               dv = \"proportion_recalled\") %&gt;%\n    as.data.table()\n})\n\n\n\n# run ANOVA\nrecall_aov &lt;- aov(proportion_recalled ~ block_type*encoding_recall*study_instruction + Error(ID/(study_instruction*encoding_recall)), data = recall_data_subject)\n\n# save printable summaries\nrecall_apa_print &lt;- papaja::apa_print(recall_aov)\n\nknitr::kable(xtable(summary(recall_aov)))\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nblock_type\n1\n0.5548501\n0.5548501\n5.4095555\n0.0232590\n\n\nResiduals\n63\n6.4618166\n0.1025685\nNA\nNA\n\n\nstudy_instruction\n2\n0.9988604\n0.4994302\n12.7054125\n0.0000094\n\n\nblock_type:study_instruction\n2\n0.0112366\n0.0056183\n0.1429286\n0.8669563\n\n\nResiduals\n126\n4.9528660\n0.0393085\nNA\nNA\n\n\nencoding_recall\n1\n0.6293447\n0.6293447\n26.5401370\n0.0000028\n\n\nblock_type:encoding_recall\n1\n0.0156288\n0.0156288\n0.6590838\n0.4199405\n\n\nResiduals\n63\n1.4939153\n0.0237129\nNA\nNA\n\n\nencoding_recall:study_instruction\n2\n0.0689459\n0.0344729\n1.3843235\n0.2542764\n\n\nblock_type:encoding_recall:study_instruction\n2\n0.0711335\n0.0355667\n1.4282476\n0.2435827\n\n\nResiduals\n126\n3.1376984\n0.0249024\nNA\nNA"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#write-up",
    "href": "vignettes/data-analysis/E1_C_analysis.html#write-up",
    "title": "Experiment 1C: SONA participants",
    "section": "Write-up",
    "text": "Write-up\n\n# use data.table \n\n#t &lt;- as.data.table(Accuracy$means$`encoding_stimulus_time:encoding_instruction`)\n#t[encoding_stimulus_time==500 & encoding_instruction == \"F\"]$mean_correct"
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#results",
    "href": "vignettes/data-analysis/E1_C_analysis.html#results",
    "title": "Experiment 1C: SONA participants",
    "section": "Results",
    "text": "Results\nWe computed proportion correct recalled for each participant in each condition of the design. The proportions were submitted to a 3 (Encoding Question: Case, Semantic, Self) x 2 (Retrieval Practice: Yes, No) x 2 (Question Order: Blocked, Mixed) mixed factorial design with Encoding Question, and Retrieval Practice as within-subject factors, and Question Order as the sole between-subject factor. Mean proportions of correctly recalled words in each condition is shown in Figure X. We adopted an alpha criterion of .05 for all statistical tests.\nThere was a main effect of encoding question, \\(F(2, 126) = 12.71\\), \\(\\mathit{MSE} = 0.04\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .059\\). Mean proportion recall was lowest in the case condition (M = 0.154, SEM = 0.017),higher for the semantic condition (M = 0.203, SEM = 0.019), and highest for the self condition (M = 0.277, SEM = 0.02).\nThe retrieval practice effect was also significant, \\(F(1, 63) = 26.54\\), \\(\\mathit{MSE} = 0.02\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .038\\). Mean proportion recall was lower for items that did not receive retrieval practice (M = 0.171, SEM = 0.015), compared to items that did receive retrieval practice (M = 0.251, SEM = 0.016).\nFinally, there was a main effect of block type, \\(F(1, 63) = 5.41\\), \\(\\mathit{MSE} = 0.10\\), \\(p = .023\\), \\(\\hat{\\eta}^2_G = .033\\). Mean proportion recall was lower for the blocked (M = 0.176, SEM = 0.014), than mixed conditions (M = 0.252, SEM = 0.017).\nNo other main effects or interactions reached significance."
  },
  {
    "objectID": "vignettes/data-analysis/E1_C_analysis.html#save-data",
    "href": "vignettes/data-analysis/E1_C_analysis.html#save-data",
    "title": "Experiment 1C: SONA participants",
    "section": "save data",
    "text": "save data\n\nsave.image(\"data/E1_C.RData\")"
  },
  {
    "objectID": "vignettes/data-analysis/E1_A.html",
    "href": "vignettes/data-analysis/E1_A.html",
    "title": "Experiment 1A: Amazon Turk Master’s Participants",
    "section": "",
    "text": "Data collected 4/19/23\nData were not usable due to most participants not completing the task. Participants were recruited from Amazon’s Mechanical Turk with minimal restrictions. The data are not included here or analysed further. This script also a generates a prediction graph."
  },
  {
    "objectID": "vignettes/data-analysis/E1_A.html#save-data",
    "href": "vignettes/data-analysis/E1_A.html#save-data",
    "title": "Experiment 1A: Amazon Turk Master’s Participants",
    "section": "save data",
    "text": "save data\n\nsave.image(\"data/E1_A.RData\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Contributors to this project…"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "",
    "text": "Shifa Maqsood\nDepartment of Psychology, Brooklyn College of CUNY"
  },
  {
    "objectID": "index.html#encoding-focused-theories-of-the-sre",
    "href": "index.html#encoding-focused-theories-of-the-sre",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "Encoding focused theories of the SRE",
    "text": "Encoding focused theories of the SRE\nAs previously mentioned, the Rogers et al. (1977) study was an attempt to replicate and extend empirical work (Craik & Tulving, 1975) providing evidence for the levels of processing principle (Craik & Lockhart, 1972). The levels of processing principle is the very general idea that memorability is influenced by depth of processing during encoding. Specifically, deeper processing during encoding yields better memory performance. For example, in the Craik and Tulving (1975) experiments, participants were presumed to encode words in the semantic conditions more deeply than words in the physical attribute or rhyming conditions. Similarly, in the self-reference effect, relating information to oneself may cause an even deeper level of processing than the semantics condition. On this view, the self-reference effect occurs because relating information to oneself strengthens memory traces through a deep level of meaningful processing. The strengthened trace is assumed to be less vulnerable to decay and thus more available for later recall.\nOrganizational encoding processes have also been forwarded as an explanation of the self-reference effect. Klein and Kihlstrom (1986) posited that self reference promotes categorical organization as the participants organize the words into two categories during the encoding phase: words that describe them and words that do not describe them. The act of categorizing words during encoding was assumed to provide additional cues that would facilitate later recall. They provided support for this idea by showing no difference in recall when semantics and self-reference were both equated to promote active categorization of list words.\nNevertheless, it can not be argued that organization is solely responsible for self-referential processing since non-depressed subjects remembered more non-depressed content than mildly depressed subjects who remembered both non-depressed and depressed content (Kuiper & Derry, 1982). These findings support a role for elaboration processes in the self-reference effect. For example, mildly depressed subjects remembered more depressed adjectives than non-depressed subjects. This finding is consistent with the idea that depressed adjectives were recalled more because they were compatible with the self-schema of the depressed individuals leaving an elaborate trace for recall. Therefore, it is possible that both, elaborative and organizational processes contribute to great recall of self-referential information.\nKlein and Loftus (1988) found that self-reference tasks performed similarly to both organizational and elaborative processes, however they were unable to infer to which degree either process contributes to the SRE. In elaborative processing, the word is encoded in reference to “item-specific” information present in the memory which leads to more than one retrieval route established for each stimulus word during encoding for later recall. Whereas in organization processing, the stimulus list words are organized in category labels in a relation to each other which are later recalled in a cluster.\nThere have been other attempts to understand the basis for SRE, one of which was proposed by Ganellen and Carver (1985) who argues for several other mediators being responsible for the incidental encoding induced by the self-reference effect. Ganellen and Carver (1985) hypothesized that self-referent encoding is dependent on emotions the stimulus produces during encoding, the importance of the stimulus to the subject, and its distinctiveness. However their results yielded no relation of these predictor variables to the self-reference effect in their experiment which led to the possible implication that cognitive processes underlying self-reference are distinct from judgmental or emotional processes.\nAlso diverging from the depth of processing paradigm, Bellezza and Hoyt (1992) proposed self-schema as an organization of internal cues which then associate personal experiences with new information and these cues are then retrieved during recall. However, Bellezza (1984) showed that participants only recalled about half of the trait words they had associated with their personal experiences. To conclude, the research on the processes behind the self-reference seems to be inconclusive despite it being a robust phenomenon which has been replicated in many studies."
  },
  {
    "objectID": "index.html#retrieval-focused-theories-of-the-sre",
    "href": "index.html#retrieval-focused-theories-of-the-sre",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "Retrieval focused theories of the SRE",
    "text": "Retrieval focused theories of the SRE\nThere has been more emphasis on encoding than retrieval processes in the self-reference effect. Retrieval refers to processes that bring information from the past to mind in the current context. In general, retrieval of memory traces is facilitated when cues in the current context match well with cues from the encoding context, and retrieval is impaired when cues between the current context and a previous one mismatch. This matching rule is supported by context-dependent memory phenomena (Godden & Baddeley, 1975), the encoding specificity principle (Tulving & Thomson, 1973), and the transfer-appropriate processing principle (Morris et al., 1977).\nThis thesis proposes that retrieval processes may play an important role in the self-reference effect. For example, according to the matching rule, participants will have better recall when the retrieval context matches well with the encoding context. In general, studies of the self-reference effect do not manipulate retrieval conditions. Typical studies involve a free-recall phase where participants generate as many words from the study list as possible. During this phase participants are free to rely on any cues, including self-generated ones, to prompt recall. If participants were naturally biased toward thinking about themselves during the recall phase, this bias would match well with the processing associated with words presented in the self-reference condition, and could provide additional support for retrieving words in the self-reference condition compared to other conditions.\nRetrieval processes may also be involved during the encoding phase. For example, retrieval practice is known to improve memorability more than multiple study attempts. For example, Roediger III and Karpicke (2006) had participants study paragraphs about undergraduate level concepts. Some paragraphs were allowed to be studied twice, and other paragraphs were only studied once followed by a quiz about the concepts. They found that concepts that were quizzed once were better remembered over the long term than concepts that were studied twice. A general interpretation of the retrieval practice effect is that remembering a piece of information is like a skill that requires specific cognitive actions. Quizzing prompts people to engage in the specific actions necessary to retrieve information, and this form of practice develops the skill necessary to retrieve the information at a later date.\nA related explanation is that as the learner tries to bring the information to their mind during each test, the diagnosticity of the retrieval cues improves by the strengthening of the match between the cue and its target (Karpicke, 2012). Proponents of elaborative encoding have argued that elaboration of the stimuli during retrieval produces mediators and additional retrieval cues which facilitate the recall during testing. However, Karpicke and Smith (2012) observed that retrieval practice is a separate mechanism which can not be attributed to elaborative encoding. In their experiment 4, there were identical twin pairs presented during learning to inhibit mediators and the repeated retrieval condition score was reported to be 99.6%. Furthermore, retrieval practice also produced higher recall than elaborative studying even when subjects were instructed to draw concept maps, which are largely associated with elaboration, at the final test. (Karpicke & Blunt, 2011).\nThis thesis proposes and tests the possibility that the retrieval practice may be contributing to the self-reference effect. Specifically, it is possible that the self-reference encoding condition is confounded with retrieval practice. For example, consider the subjective experience involved in a typical self-reference judgment asking participants whether an adjective, such as “nice”, describes themselves. Participants may begin an internal narrative asking themselves, “Am I nice?”, “Maybe, I’m nice, but I’m not that nice”, etc. This narrative involves repeatedly stating the to-be-remembered word, which provides multiple retrieval practice attempts. Participants may not engage in such a complex inner monologue for the other conditions, especially when the judgment can be made more directly. On this view, the self-reference effect could reflect an advantage for words that were given retrieval practice in the self-reference condition compared to words that were not practiced in the other conditions. The purpose of the experiments reported in this thesis is to investigate this hypothesis directly by explicitly manipulating retrieval practice across all conditions."
  },
  {
    "objectID": "index.html#methods",
    "href": "index.html#methods",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "Methods",
    "text": "Methods\n\nParticipants.\nParticipants were recruited from Amazon’s Mechanical Turk, but due to several issues it was unclear how many legitimate human participants were recruited. The experiment was approved by the Brooklyn College Institutional Review Board.\n\n\nMaterials.\nA list of person-descriptive words was obtained from (Chandler, 2018). The list of words was filtered to exclude any words containing punctuation, and words considered derogatory and otherwise objectionable. The total stimulus set had 375 words. These words were categorized by Chandler (2018) in terms of likeableness. There were 173 high likeable words, and 202 low likeable words.\n\n\nDesign.\nThe experimental design was a 3x2x2 mixed factorial. The encoding judgment task was a within-subject factor with three levels: structural, semantic, and self-reference. Retrieval practice was also a within-subject factor with two levels: retrieval practice vs. no retrieval practice. Last the encoding judgment tasks were presented to participants in either a blocked or mixed design. The dependent variable was the number of words recalled.\n12 unique words (6 high and 6 low likeable) were randomly chosen from the stimulus set for each of the three conditions (36 words in total). Four additional filler items were inserted at the beginning and end of the encoding phase. The intention was to randomly assign half of the words for each judgment task to the retrieval practice condition, and the other half to the no-retrieval practice condition. However, a mistake in the experiment script caused .33 of the words to be assigned to the retrieval practice condition and .67 words to the no-retrieval practice condition. This error was corrected in the following experiments.\n\n\nApparatus.\nThe experiment was programmed in JavaScript and HTML using JsPsych (de Leeuw, 2015). Just Another Tool for Online Studies (JATOS) was used to host this experiment online (Lange et al., 2015). The source code for the experiments is available from the project website.\n\n\nProcedure.\nParticipants were recruited from Amazon’s Mechanical Turk. They completed a consent form followed by a demographics questionnaire and task instructions. The task instructions stated, “In this phase you will make judgments about words that describe personality characteristics or traits. Sometimes you will be asked to remember words that were just shown to you. There are 44 words to judge. After this phase you will be given a memory test for all of the words you saw. Press any key to begin.”\nFollowing the instructions, participants completed the encoding phase. On each trial a cue question indicating the word judgment task was presented on screen for 3000 ms. There were three possible cue questions: “Is the following word written in upper case?”, “Does the following word have a positive meaning?”, and “Would you use the following word to describe yourself?”. Next, the target word appeared on screen underneath the cue question, along with two buttons to respond “yes” or “no”, all of which remained on screen until a response was made. There was an intertrial interval of 1000 ms. For words assigned to the retrieval practice condition a recall prompt appeared prior to the next trial. The recall prompt stated, “Recall the last word, type the last word that you judged.” Participants were shown a box with a cursor and proceeded to type their response. They pressed a button to continue to the next trial. There were a total of 44 encoding trials.\nIn phase 2 of the experiment, participants were instructed to recall as many of the words as they could. Participants were shown an instruction screen stating, “Phase II instructions. In this phase you will be given a recall memory test. You made judgments about 44 words. Your task is now to recall as many words as you can by typing out each word. Press any key to begin.” Next participants were shown a screen with instructions and a text entry box. The instructions read, “Recall each word. You were shown 44 words, try to recall as many words as possible. Type each word separated by a space. Your responses will be shown in the box below.”\nParticipants pressed a button to continue when they could not recall additional words. At this time, a second free recall phase began and participants were asked to try one more time to recall any additional words. The experiment ended after the final recall phase.\n\n\nData-Exclusion.\nOur experiment was conducted online and it was completed by participants on their web browsers. Although there were specific instructions at the beginning of the experiment, there was a possibility that participants completed and submitted the experiment without following the instructions. Thus, we set criteria for excluding those participants whose responses indicated that they did not follow the instructions to complete the tasks. During the study phase, part one of the experiment, participants were instructed to click on either, “Yes” or “No” button. There were three conditions: structural, semantics and self. In the structural condition, the questions asked if the word displayed on screen was in uppercase or lowercase. We judged the response to the questions in this condition to be the baseline for our criteria as this condition served as the participant’s ability to attend to instructions. We excluded participants who scored lower than 70% on structural judgement questions. A total of 16 participants were excluded. We also checked for response bias to make sure that the participants were not randomly choosing the “Yes” or “No” option as their responses to the question."
  },
  {
    "objectID": "index.html#results-and-discussion",
    "href": "index.html#results-and-discussion",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "Results and Discussion",
    "text": "Results and Discussion\nThe data analysis suggested that many of the participants may not have been completing the study as intended. First, a large proportion of participants were scored at or near chance on the letter size judgment task. Second, recall rates were very low overall, and several participants typed nonsense responses. Third, the response patterns suggested that some number of participants were completing the experiment multiple times under different user names. The data collected for the pilot study also revealed an error in the program which did not assign an equal number of trials to the retrieval practice and no-retrieval practice conditions. For these reasons, the data for the pilot study are not reported.\nThere are several known issues with recruiting participants from Amazon’s Mechanical Turk (Rodd, 2023). The pilot experiment recruited participants with minimal filtering. The next experiment addressed these issues with recruitment."
  },
  {
    "objectID": "index.html#methods-1",
    "href": "index.html#methods-1",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "Methods",
    "text": "Methods\n\nParticipants.\nFor experiment 1b, A total of 53 participants were recruited from Amazon’s Mechanical Turk. Mean age was 46.1 (range = 29 to 69 ). There were 30 females, and 23 males. There were 49 right-handed participants, and no left or both handed participants. 28 participants reported normal vision, and 25 participants reported corrected-to-normal vision. 52 participants reported English as a first language, and 1 participant reported English as a second language.\nFor experiment 1c, A total of 65 participants were recruited from Amazon’s Mechanical Turk. Mean age was 21.6 (range = 18 to 49 ). There were 48 females, and 16 males. There were 56 right-handed participants, and 8 left or both handed participants. 30 participants reported normal vision, and 28 participants reported corrected-to-normal vision. 42 participants reported English as a first language, and 22 participants reported English as a second language.\n\n\nMaterials.\nThe same materials as described in the pilot experiment were used in experiment 1b and 1c.\n\n\nDesign.\nThe same 3x2x2 mixed factorial design as described in the pilot experiment was used in experiments 1b and 1c.\n\n\nApparatus.\nThe apparatus was the same as the pilot experiment.\n\n\nProcedure.\nThe procedure was the same as before with the following differences.\nThe instructions given during the encoding phase further specified that, “Important. There is a memory test after this phase. Please do not use external aids to help your performance. For example, please do not write down the words or take screenshots. The experiment is aimed at measuring unaided memory processes. Press any key to begin.”\nAt the end of the experiment participants were presented with the following debriefing statement and questions: “Thanks for participating, we are planning on running similar experiments in the future, and we are interested in your feedback. Did you use any external memory aids like writing down the words or taking screenshots? Thanks for letting us know. Were you able to give this task your full attention, or did you get interrupted? Thanks for letting us know. Did you run into issues with the task, or other issues that might have impacted your performance?”\n\n\nData-Exclusion.\nWe used the same exclusion procedure as described previously. No participants were removed from experiment 1b and 1 participant was removed from experiment 1c.\nWe used R (Version 4.3.1; R Core Team, 2022) and the R-packages conflicted (Version 1.2.0; R-conflicted?), data.table (Version 1.14.8; Dowle & Srinivasan, 2022), dplyr (Version 1.1.3; Wickham, François, et al., 2023), flextable (Version 0.9.3; R-flextable?), forcats (Version 1.0.0; Wickham, 2023), ftExtra (Version 0.6.1; R-ftExtra?), ggplot2 (Version 3.4.2; Wickham, 2016), jsonlite (Version 1.8.7; Ooms, 2014), knitr (Version 1.44; R-knitr?), lubridate (Version 1.9.2; Grolemund & Wickham, 2011), officer (Version 0.6.2; R-officer?), papaja (Version 0.1.1; Aust & Barth, 2022), purrr (Version 1.0.2; Wickham & Henry, 2023), readr (Version 2.1.4; Wickham, Hester, et al., 2023), stringr (Version 1.5.0; Wickham, 2022), tibble (Version 3.2.1; Müller & Wickham, 2022), tidyr (Version 1.3.0; Wickham, Vaughan, et al., 2023), tidyverse (Version 2.0.0; Wickham et al., 2019), tinylabels (Version 0.2.3; Barth, 2022), and xtable (Dahl et al., 2019; Version 1.8.4; R-flextable?) for all our analyses. An alpha criterion of .05 was adopted for all statistical tests."
  },
  {
    "objectID": "index.html#results",
    "href": "index.html#results",
    "title": "Is The Self Reference Effect a Retrieval Practice Phenomenon?",
    "section": "Results",
    "text": "Results\n\nExperiment 1b: Amazon Mechanical Turk Master’s\nWe computed proportion of words correctly recalled for each participant in each condition of the design. The proportions were submitted to a 3 (Encoding Question: Case, Semantic, Self) x 2 (Retrieval Practice: Yes, No) x 2 (Question Order: Blocked, Mixed) mixed factorial design with Encoding Question, and Retrieval Practice as within-subject factors, and Question Order as the sole between-subject factor. Mean proportions of correctly recalled words in each condition are shown in Figure @ref(fig:E1Bresults).\n\n\n\n\nMean proportion words recalled in Experiment 1b as a function of encoding question, retrieval practice, and blocking variables.\n\n\n\n\n\nThere was a main effect of encoding question, F(2, 102) = 12.99, \\mathit{MSE} = 0.03, p &lt; .001, \\hat{\\eta}^2_G = .059. Mean proportion recall was lowest in the case condition (M = 0.131, SEM = 0.017), and at similar higher levels for the semantic (M = 0.239, SEM = 0.022), and self condition (M = 0.245, SEM = 0.023).\nThe retrieval practice effect was also significant, F(1, 51) = 4.18, \\mathit{MSE} = 0.03, p = .046, \\hat{\\eta}^2_G = .008. Mean proportion recall was lower for items that did not receive retrieval practice (M = 0.187, SEM = 0.017), compared to items that did receive retrieval practice (M = 0.223, SEM = 0.017).\nNo other main effects or interactions reached significance.\n\n\nExperiment 1c: Brooklyn College SONA\nThe results from experiment 1c were submitted to the same analysis as above. Mean proportions of correctly recalled words in each condition are shown in Figure @ref(fig:E1Cresults).\n\n\n\n\nMean proportion words recalled in Experiment 1c as a function of encoding question, retrieval practice, and blocking variables.\n\n\n\n\n\nThere was a main effect of encoding question, F(2, 126) = 12.71, \\mathit{MSE} = 0.04, p &lt; .001, \\hat{\\eta}^2_G = .059. Mean proportion recall was lowest in the case condition (M = 0.154, SEM = 0.017),higher for the semantic condition (M = 0.203, SEM = 0.019), and highest for the self condition (M = 0.277, SEM = 0.02).\nThe retrieval practice effect was also significant, F(1, 63) = 26.54, \\mathit{MSE} = 0.02, p &lt; .001, \\hat{\\eta}^2_G = .038. Mean proportion recall was lower for items that did not receive retrieval practice (M = 0.171, SEM = 0.015), compared to items that did receive retrieval practice (M = 0.251, SEM = 0.016).\nFinally, there was a main effect of block type, F(1, 63) = 5.41, \\mathit{MSE} = 0.10, p = .023, \\hat{\\eta}^2_G = .033. Mean proportion recall was lower for the blocked (M = 0.176, SEM = 0.014), than mixed conditions (M = 0.252, SEM = 0.017).\nNo other main effects or interactions reached significance.\n\n\nPost-hoc power analysis\nThe results from Experiment 1b were used to conduct a simulation-based post-hoc power analysis. The purpose of the power analysis was to estimate the smallest effect size of interest that the design was capable of detecting. Experiment 1b did not show evidence of the expected self-reference effect, specifically measured as a difference between the self and semantic encoding conditions. One possibility is that our design was not sensitive enough to detect a difference between those conditions.\nThe results of the power analysis indicated that the design had greater than power .8 to detect differences in recall proportions greater than .1 with n = 100. The design had power greater than .8 to detect differences in recall proportions greater than .05 with n = 200.\nThe power analysis suggests that individual experiment may have been under-powered to detect the self-reference effect. To increase power by increasing the number of participants, the following analysis collapsed over the results from experiment 1b and 1c.\n\n\nCombined analysis\n\n\n\n\nMean proportion words recalled collapsed across Experiment 1b and c, and collapsed over the blocking variable, as a function of encoding question and retrieval practice.\n\n\n\n\n\nThere was a main effect of encoding question, F(2, 234) = 23.25, \\mathit{MSE} = 0.04, p &lt; .001, \\hat{\\eta}^2_G = .052. Mean proportion recall was lowest in the case condition (M = 0.143, SEM = 0.012),higher for the semantic condition (M = 0.219, SEM = 0.014), and highest for the self condition (M = 0.263, SEM = 0.015).\nThe retrieval practice effect was also significant, F(1, 117) = 26.36, \\mathit{MSE} = 0.02, p &lt; .001, \\hat{\\eta}^2_G = .021. Mean proportion recall was lower for items that did not receive retrieval practice (M = 0.178, SEM = 0.011), compared to items that did receive retrieval practice (M = 0.239, SEM = 0.012).\nThe interaction between retrieval practice and encoding question approached significance, F(2, 234) = 2.58, \\mathit{MSE} = 0.02, p = .078, \\hat{\\eta}^2_G = .004.\nThe main hypotheses from figure @ref(fig:predictions) were investigated with simple effects comparisons. There are two ways to evaluate whether the self-reference effect was influenced by the retrieval practice manipulation.\nFirst, looking solely at the self-reference condition, recall proportions in the retrieval practice condition were not higher than the no-retrieval practice, M_D = -0.03, 95% CI [-0.08, 0.02], t(117) = -1.33, p = .185. This absence of a retrieval practice benefit for the self-reference condition is consistent with the hypothesis that participants were already engaging in retrieval practice as a part of making the self-reference judgment.\nSecond, a self-reference benefit over the semantic judgment was observed in the no-retrieval practice condition, M_D = 0.06, 95% CI [0.01, 0.10], t(117) = 2.50, p = .014. However, a self-reference benefit over the semantic judgment was not observed in the retrieval practice condition, M_D = 0.03, 95% CI [-0.02, 0.08], t(117) = 1.23, p = .220"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html",
    "href": "vignettes/data-analysis/E1_B_analysis.html",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "",
    "text": "The purpose of this document is to provide an in-principle pipeline for reproducible analysis.\nData collected 5/26/23 (Mturk masters)\nThe first version of this experiment (1A) had a couple issues. The proportion of recall vs no-recall trials during encoding was supposed to be equal (6 and 6 for each question condition), but it was not (4 recall vs 8 no recall). There were supposed to be 3 filler items before and after the main lists, but there were three at the beginning and two at the end. This experiment fixes those issues.\nThe first experiment was conducted on Amazon’s Mechanical Turk with few restrictions. Some of the responses to the free recall task indicated participants were not performing the experiment (e.g., typing in paragraph responses, or nonsense).\nThis experiment again recruited participants from Amazon’s Mechanical Turk, but used the following restriction: Masters, US, 95% hit approval, more than 200 hits"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#import-data",
    "href": "vignettes/data-analysis/E1_B_analysis.html#import-data",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Import Data",
    "text": "Import Data\n\n# Read the text file from JATOS ...\nread_file('data/E1B_self_reference_deID.JSON') %&gt;%\n  # ... split it into lines ...\n  str_split('\\n') %&gt;% first() %&gt;%\n  # ... filter empty rows ...\n  discard(function(x) x == '') %&gt;%\n  # ... parse JSON into a data.frame\n  map_dfr(fromJSON, flatten=T) -&gt; all_data"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#demographics",
    "href": "vignettes/data-analysis/E1_B_analysis.html#demographics",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Demographics",
    "text": "Demographics\n\nlibrary(tidyr)\n\ndemographics &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-html-form\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response) %&gt;%\n  mutate(age = as.numeric(age))\n\nage_demographics &lt;- demographics %&gt;%\n  summarize(mean_age = mean(age),\n            sd_age = sd(age),\n            min_age = min(age),\n            max_age = max(age))\n\nfactor_demographics &lt;- apply(demographics[-1], 2, table)\n\nA total of 53 participants were recruited from Amazon’s Mechanical Turk. Mean age was 46.1 (range = 29 to 69 ). There were 30 females, and 23 males. There were 49 right-handed participants, and NA left or both handed participants. 28 participants reported normal vision, and 25 participants reported corrected-to-normal vision. 52 participants reported English as a first language, and 1 participants reported English as a second language."
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#pre-processing",
    "href": "vignettes/data-analysis/E1_B_analysis.html#pre-processing",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Pre-processing",
    "text": "Pre-processing\nWe were were interested in analyzing data from participants who appeared to engage with the task as intended. To identify participants for inclusion we used accuracy data from the case judgment task. We included participants if their accuracy was 70% or greater.\n\nCase judgment accuracy\nGet case judgment accuracy for all participants.\n\ncase_judgment &lt;- all_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         study_instruction == \"case\") %&gt;%\n  mutate(response = as.character(unlist(response))) %&gt;%\n  mutate(accuracy = case_when(\n    response == \"0\" & letter_case == \"upper\" ~ 1,\n    response == \"1\" & letter_case == \"upper\" ~ 0,\n    response == \"0\" & letter_case == \"lower\" ~ 0,\n    response == \"1\" & letter_case == \"lower\" ~ 1\n         )) %&gt;%\n  group_by(ID) %&gt;%\n  summarise(percent_correct = mean(accuracy))\n\nggplot(case_judgment, aes(x=percent_correct))+\n  geom_histogram() +\n  geom_vline(xintercept=.7)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#post-task-questions",
    "href": "vignettes/data-analysis/E1_B_analysis.html#post-task-questions",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "post-task questions",
    "text": "post-task questions\n\npost_questions &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-text\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#all-exclusions",
    "href": "vignettes/data-analysis/E1_B_analysis.html#all-exclusions",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "All exclusions",
    "text": "All exclusions\nIdentify any participants that would be excluded.\n\nall_excluded &lt;- case_judgment %&gt;%\n  filter(percent_correct &lt; .7) %&gt;%\n  select(ID) %&gt;%\n  pull()\n\nlength(all_excluded)\n\n[1] 0\n\nfiltered_data &lt;- all_data %&gt;%\n  filter(ID %in% all_excluded == FALSE)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#define-helper-functions",
    "href": "vignettes/data-analysis/E1_B_analysis.html#define-helper-functions",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Define Helper functions",
    "text": "Define Helper functions\nTo do, consider moving the functions into the R package for this project\n\n# attempt general solution\n\n## Declare helper functions\n\n################\n# get_mean_sem\n# data = a data frame\n# grouping_vars = a character vector of factors for analysis contained in data\n# dv = a string indicated the dependent variable colunmn name in data\n# returns data frame with grouping variables, and mean_{dv}, sem_{dv}\n# note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv\n\nget_mean_sem &lt;- function(data, grouping_vars, dv, digits=3){\n  a &lt;- data %&gt;%\n    group_by_at(grouping_vars) %&gt;%\n    summarize(\"mean_{ dv }\" := round(mean(.data[[dv]]), digits),\n              \"sem_{ dv }\" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),\n              .groups=\"drop\")\n  return(a)\n}\n\n################\n# get_effect_names\n# grouping_vars = a character vector of factors for analysis\n# returns a named list\n# list contains all main effects and interaction terms\n# useful for iterating the computation means across design effects and interactions\n\nget_effect_names &lt;- function(grouping_vars){\n  effect_names &lt;- grouping_vars\n  if( length(grouping_vars &gt; 1) ){\n    for( i in 2:length(grouping_vars) ){\n      effect_names &lt;- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=\":\"))\n    }\n  }\n  effects &lt;- strsplit(effect_names, split=\":\")\n  names(effects) &lt;- effect_names\n  return(effects)\n}\n\n################\n# print_list_of_tables\n# table_list = a list of named tables\n# each table is printed \n# names are header level 3\n\nprint_list_of_tables &lt;- function(table_list){\n  for(i in 1:length(table_list)){\n    cat(\"###\",names(table_list[i]))\n    cat(\"\\n\")\n    print(knitr::kable(table_list[[i]]))\n    cat(\"\\n\")\n  }\n}"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#study-phase-immediate-recall",
    "href": "vignettes/data-analysis/E1_B_analysis.html#study-phase-immediate-recall",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Study phase immediate recall",
    "text": "Study phase immediate recall\n\n# get recall proportion correct for each participant\nstudy_phase_recall &lt;-  filtered_data %&gt;%\n  filter(phase == \"study_recall\",\n         encoding_recall == \"recall\") %&gt;%\n  separate(col = paragraph,\n           into = c(\"first_word\",\"second_word\"),\n           sep = \" \",\n           remove = FALSE,\n           extra = \"merge\") %&gt;%\n  mutate(accuracy = tolower(target_word) == tolower(first_word),\n         study_instruction = factor(study_instruction, levels= c(\"case\",\"semantic\",\"self\"))) %&gt;%\n  group_by(ID,study_instruction) %&gt;%\n  summarize(percent_correct = mean(accuracy))\n\n# get means in each question condition\nstudy_phase_recall_means &lt;- get_mean_sem(study_phase_recall,\n             grouping_vars = c(\"study_instruction\"),\n             dv = \"percent_correct\")\n\n# run ANOVA\nstudy_phase_recall &lt;- study_phase_recall %&gt;%\n  ungroup() %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction))\n\nstudy_phase_recall_aov &lt;- aov(percent_correct ~ study_instruction + Error(ID/study_instruction),\n    study_phase_recall)\n\n# save printable summaries\nstudy_phase_recall_apa_print &lt;- papaja::apa_print(study_phase_recall_aov)\n\nknitr::kable(study_phase_recall_means)\n\n\n\n\nstudy_instruction\nmean_percent_correct\nsem_percent_correct\n\n\n\n\ncase\n0.903\n0.023\n\n\nsemantic\n0.950\n0.012\n\n\nself\n0.947\n0.016\n\n\n\n\n\nDuring the encoding phase participants attempted to immediately recall half of the words following the primary judgment. We computed proportion of correctly recalled words for each participant separately in each encoding question condition. These means were submitted to a one-way repeated measures ANOVA, with question type as the sole factor. Mean proportion correctly recalled was 0.903 in the case judgment, 0.95 in the semantic judgment, and 0.947 in the self-reference condition; \\(F(2, 104) = 3.57\\), \\(\\mathit{MSE} = 0.01\\), \\(p = .032\\), \\(\\hat{\\eta}^2_G = .028\\)."
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#study-phase-word-judgment",
    "href": "vignettes/data-analysis/E1_B_analysis.html#study-phase-word-judgment",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Study phase word judgment",
    "text": "Study phase word judgment\n\n# get recall proportion correct for each participant\nstudy_phase_judgment &lt;-  filtered_data %&gt;%\n  \n  filter(phase == \"main_study\",\n         encoding_trial_type == \"study_word\")  %&gt;%\n  \n  mutate(accuracy = case_when(study_instruction == \"case\" & \n                                letter_case == \"lower\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"case\" & \n                                letter_case == \"lower\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"case\" & \n                                letter_case == \"upper\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"case\" & \n                                letter_case == \"upper\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"low\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"low\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"high\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"semantic\" & \n                                likeable == \"high\" &\n                                response == 1 ~ FALSE,\n                              study_instruction == \"self\" & \n                                likeable == \"low\" &\n                                response == 0 ~ FALSE,\n                              study_instruction == \"self\" & \n                                likeable == \"low\" &\n                                response == 1 ~ TRUE,\n                              study_instruction == \"self\" & \n                                likeable == \"high\" &\n                                response == 0 ~ TRUE,\n                              study_instruction == \"self\" & \n                                likeable == \"high\" &\n                                response == 1 ~ FALSE\n                              ),\n         study_instruction = factor(study_instruction, \n                                    levels= c(\"case\",\"semantic\",\"self\"))) %&gt;%\n  \n  group_by(ID,study_instruction) %&gt;%\n  \n  summarize(percent_correct = mean(accuracy)) %&gt;%\n  ungroup()\n\n# get means in each question condition\nstudy_phase_judgment_means &lt;- get_mean_sem(study_phase_judgment,\n             grouping_vars = c(\"study_instruction\"),\n             dv = \"percent_correct\")\n\nknitr::kable(study_phase_judgment_means)\n\n\n\n\nstudy_instruction\nmean_percent_correct\nsem_percent_correct\n\n\n\n\ncase\n0.998\n0.002\n\n\nsemantic\n0.973\n0.009\n\n\nself\n0.780\n0.026\n\n\n\n\n\nFor completeness we report mean performance in the encoding phase for each of the word judgment condition. See above table."
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#recall-test",
    "href": "vignettes/data-analysis/E1_B_analysis.html#recall-test",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Recall Test",
    "text": "Recall Test\n\n# obtain recall data from typed answers\n\nrecall_data &lt;- filtered_data %&gt;%\n  filter(phase %in% c(\"recall_1\",\"recall_2\") == TRUE ) %&gt;%\n  select(ID,phase,paragraph) %&gt;%\n  pivot_wider(names_from = phase,\n              values_from = paragraph) %&gt;%\n  mutate(recall_1 = paste(recall_1,recall_2,sep = \" \")) %&gt;%\n  select(ID,recall_1) %&gt;%\n # separate_longer_delim(cols = recall_1,\n #                        delim = \" \") %&gt;%\n  mutate(recall_1 = tolower(recall_1)) %&gt;%\n  mutate(recall_1 = gsub(\"[^[:alnum:][:space:]]\",\"\",recall_1))\n\nencoding_words_per_subject &lt;- filtered_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         phase == \"main_study\")\n\nrecall_data &lt;- left_join(encoding_words_per_subject,recall_data,by = 'ID') %&gt;%\n  mutate(recall_1 = strsplit(recall_1,\" \"))\n\n# implement a spell-checking method\n\nrecall_success &lt;- c()\nmin_string_distance &lt;- c()\nfor(i in 1:dim(recall_data)[1]){\n  recalled_words &lt;- unlist(recall_data$recall_1[i])\n  recalled_words &lt;- recalled_words[recalled_words != \"\"]\n  if (length(recalled_words) == 0 ) recalled_words &lt;- \"nonerecalled\"\n  recall_success[i] &lt;- tolower(recall_data$target_word[i]) %in% recalled_words\n  min_string_distance[i] &lt;- min(sapply(recalled_words,FUN = function(x) {\n  stringdist::stringdist(a=x,b = tolower(recall_data$target_word[i]), method = \"lv\")\n}))\n}\n\n# recall proportion correct by subject\n# correct for unequal conditions. 4 words in recall, 8 words in no recall\n\nrecall_data_subject &lt;- recall_data %&gt;%\n  mutate(recall_success = recall_success,\n         min_string_distance = min_string_distance) %&gt;%\n  mutate(close_recall = min_string_distance &lt;= 2) %&gt;%\n  group_by(ID,study_instruction,encoding_recall,block_type) %&gt;%\n  summarise(number_recalled = sum(recall_success),\n            number_close_recalled = sum(close_recall)) %&gt;%\n  ungroup() %&gt;%\n  mutate(proportion_recalled = case_when(encoding_recall == \"no_recall\" ~ number_close_recalled/6,\n                                         encoding_recall == \"recall\" ~ number_close_recalled/6)) %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction),\n         encoding_recall = as.factor(encoding_recall),\n         block_type = as.factor(block_type))\n\n# Condition means\nmean_recall_data &lt;- get_mean_sem(recall_data_subject,\n             c(\"study_instruction\",\"encoding_recall\", \"block_type\"),\n             \"proportion_recalled\") %&gt;%\n  ungroup() %&gt;%\n  mutate(study_instruction = factor(study_instruction,levels = c(\"case\",\"semantic\",\"self\")),\n         `Retrieval Practice` = case_when(\n           encoding_recall == \"no_recall\" ~ \"No Retrieval Practice \\n during study \\n\",\n           encoding_recall == \"recall\" ~ \"Retrieval Practice \\n during study \\n\",\n                                          ))\n\nrecall_plot &lt;- ggplot(mean_recall_data,\n       aes(x = study_instruction,\n           y = mean_proportion_recalled,\n           fill= `Retrieval Practice`))+\n  geom_bar(stat=\"identity\",position=\"dodge\",color=\"black\") +\n  geom_errorbar(aes(ymin = mean_proportion_recalled - sem_proportion_recalled,\n                    ymax = mean_proportion_recalled + sem_proportion_recalled),\n                width=.9, position=position_dodge2(width = 0.2, padding = 0.8)) +\n  ylab(\"Proportion words recalled\")+\n  xlab(\"Study Instruction\") +\n  theme_classic(base_size = 15)+\n  theme(legend.position = \"top\")+\n  facet_wrap(~block_type)\n\nrecall_plot"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#recall-test-anova",
    "href": "vignettes/data-analysis/E1_B_analysis.html#recall-test-anova",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Recall test ANOVA",
    "text": "Recall test ANOVA\n\n## Condition-level means\n# get all possible main effects and interactions\nrecall_effect_names &lt;- get_effect_names(c(\"block_type\",\"encoding_recall\", \"study_instruction\"))\n\nrecall_effect_means &lt;- lapply(recall_effect_names, FUN = function(x) {\n  get_mean_sem(data=recall_data_subject,\n               grouping_vars = x,\n               dv = \"proportion_recalled\") %&gt;%\n    as.data.table()\n})\n\n\n\n# run ANOVA\nrecall_aov &lt;- aov(proportion_recalled ~ block_type*encoding_recall*study_instruction + Error(ID/(study_instruction*encoding_recall)), data = recall_data_subject)\n\n# save printable summaries\nrecall_apa_print &lt;- papaja::apa_print(recall_aov)\n\nknitr::kable(xtable(summary(recall_aov)))\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nblock_type\n1\n0.0512463\n0.0512463\n0.3750072\n0.5430084\n\n\nResiduals\n51\n6.9693686\n0.1366543\nNA\nNA\n\n\nstudy_instruction\n2\n0.8827743\n0.4413871\n12.9864894\n0.0000095\n\n\nblock_type:study_instruction\n2\n0.0670980\n0.0335490\n0.9870785\n0.3761950\n\n\nResiduals\n102\n3.4667944\n0.0339882\nNA\nNA\n\n\nencoding_recall\n1\n0.1070056\n0.1070056\n4.1825414\n0.0460186\n\n\nblock_type:encoding_recall\n1\n0.0002541\n0.0002541\n0.0099339\n0.9209979\n\n\nResiduals\n51\n1.3047773\n0.0255839\nNA\nNA\n\n\nencoding_recall:study_instruction\n2\n0.0766946\n0.0383473\n1.7643242\n0.1764898\n\n\nblock_type:encoding_recall:study_instruction\n2\n0.0304254\n0.0152127\n0.6999230\n0.4989928\n\n\nResiduals\n102\n2.2169540\n0.0217348\nNA\nNA"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#write-up",
    "href": "vignettes/data-analysis/E1_B_analysis.html#write-up",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Write-up",
    "text": "Write-up\n\n# use data.table \n\n#t &lt;- as.data.table(Accuracy$means$`encoding_stimulus_time:encoding_instruction`)\n#t[encoding_stimulus_time==500 & encoding_instruction == \"F\"]$mean_correct"
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#results",
    "href": "vignettes/data-analysis/E1_B_analysis.html#results",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "Results",
    "text": "Results\nWe computed proportion correct recalled for each participant in each condition of the design. The proportions were submitted to a 3 (Encoding Question: Case, Semantic, Self) x 2 (Retrieval Practice: Yes, No) x 2 (Question Order: Blocked, Mixed) mixed factorial design with Encoding Question, and Retrieval Practice as within-subject factors, and Question Order as the sole between-subject factor. Mean proportions of correctly recalled words in each condition are shown in Figure X.\nThere was a main effect of encoding question, \\(F(2, 102) = 12.99\\), \\(\\mathit{MSE} = 0.03\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .059\\). Mean proportion recall was lowest in the case condition (M = 0.131, SEM = 0.017), and at similar higher levels for the semantic (M = 0.239, SEM = 0.022), and self condition (M = 0.245, SEM = 0.023).\nThe retrieval practice effect was also significant, \\(F(1, 51) = 4.18\\), \\(\\mathit{MSE} = 0.03\\), \\(p = .046\\), \\(\\hat{\\eta}^2_G = .008\\). Mean proportion recall was lower for items that did not receive retrieval practice (M = 0.187, SEM = 0.017), compared to items that did receive retrieval practice (M = 0.223, SEM = 0.017).\nNo other main effects or interactions reached significance."
  },
  {
    "objectID": "vignettes/data-analysis/E1_B_analysis.html#save-data",
    "href": "vignettes/data-analysis/E1_B_analysis.html#save-data",
    "title": "Experiment 1B: Amazon Turk Master’s Participants",
    "section": "save data",
    "text": "save data\n\nsave.image(\"data/E1_B.RData\")"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html",
    "title": "E1_Power_Analysis",
    "section": "",
    "text": "Plan for power analysis."
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#import-data",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#import-data",
    "title": "E1_Power_Analysis",
    "section": "Import Data",
    "text": "Import Data\n\n# Read the text file from JATOS ...\nread_file('data/E1B_self_reference_deID.JSON') %&gt;%\n  # ... split it into lines ...\n  str_split('\\n') %&gt;% first() %&gt;%\n  # ... filter empty rows ...\n  discard(function(x) x == '') %&gt;%\n  # ... parse JSON into a data.frame\n  map_dfr(fromJSON, flatten=T) -&gt; all_data"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#demographics",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#demographics",
    "title": "E1_Power_Analysis",
    "section": "Demographics",
    "text": "Demographics\n\nlibrary(tidyr)\n\ndemographics &lt;- all_data %&gt;%\n  filter(trial_type == \"survey-html-form\") %&gt;%\n  select(ID,response) %&gt;%\n  unnest_wider(response) %&gt;%\n  mutate(age = as.numeric(age))\n\nage_demographics &lt;- demographics %&gt;%\n  summarize(mean_age = mean(age),\n            sd_age = sd(age),\n            min_age = min(age),\n            max_age = max(age))\n\nfactor_demographics &lt;- apply(demographics[-1], 2, table)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#pre-processing",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#pre-processing",
    "title": "E1_Power_Analysis",
    "section": "Pre-processing",
    "text": "Pre-processing\n\nCase judgment accuracy\nGet case judgment accuracy for all participants.\n\ncase_judgment &lt;- all_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         study_instruction == \"case\") %&gt;%\n  mutate(response = as.character(unlist(response))) %&gt;%\n  mutate(accuracy = case_when(\n    response == \"0\" & letter_case == \"upper\" ~ 1,\n    response == \"1\" & letter_case == \"upper\" ~ 0,\n    response == \"0\" & letter_case == \"lower\" ~ 0,\n    response == \"1\" & letter_case == \"lower\" ~ 1\n         )) %&gt;%\n  group_by(ID) %&gt;%\n  summarise(percent_correct = mean(accuracy))\n\nggplot(case_judgment, aes(x=percent_correct))+\n  geom_histogram() +\n  geom_vline(xintercept=.7)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#all-exclusions",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#all-exclusions",
    "title": "E1_Power_Analysis",
    "section": "All exclusions",
    "text": "All exclusions\nno exclusions\n\nall_excluded &lt;- case_judgment %&gt;%\n  filter(percent_correct &lt; .7) %&gt;%\n  select(ID) %&gt;%\n  pull()\n\nlength(all_excluded)\n\n[1] 0\n\nfiltered_data &lt;- all_data %&gt;%\n  filter(ID %in% all_excluded == FALSE)"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#define-helper-functions",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#define-helper-functions",
    "title": "E1_Power_Analysis",
    "section": "Define Helper functions",
    "text": "Define Helper functions\nTo do, consider moving the functions into the R package for this project\n\n# attempt general solution\n\n## Declare helper functions\n\n################\n# get_mean_sem\n# data = a data frame\n# grouping_vars = a character vector of factors for analysis contained in data\n# dv = a string indicated the dependent variable colunmn name in data\n# returns data frame with grouping variables, and mean_{dv}, sem_{dv}\n# note: dv in mean_{dv} and sem_{dv} is renamed to the string in dv\n\nget_mean_sem &lt;- function(data, grouping_vars, dv, digits=3){\n  a &lt;- data %&gt;%\n    group_by_at(grouping_vars) %&gt;%\n    summarize(\"mean_{ dv }\" := round(mean(.data[[dv]]), digits),\n              \"sem_{ dv }\" := round(sd(.data[[dv]])/sqrt(length(.data[[dv]])),digits),\n              .groups=\"drop\")\n  return(a)\n}\n\n################\n# get_effect_names\n# grouping_vars = a character vector of factors for analysis\n# returns a named list\n# list contains all main effects and interaction terms\n# useful for iterating the computation means across design effects and interactions\n\nget_effect_names &lt;- function(grouping_vars){\n  effect_names &lt;- grouping_vars\n  if( length(grouping_vars &gt; 1) ){\n    for( i in 2:length(grouping_vars) ){\n      effect_names &lt;- c(effect_names,apply(combn(grouping_vars,i),2,paste0,collapse=\":\"))\n    }\n  }\n  effects &lt;- strsplit(effect_names, split=\":\")\n  names(effects) &lt;- effect_names\n  return(effects)\n}\n\n################\n# print_list_of_tables\n# table_list = a list of named tables\n# each table is printed \n# names are header level 3\n\nprint_list_of_tables &lt;- function(table_list){\n  for(i in 1:length(table_list)){\n    cat(\"###\",names(table_list[i]))\n    cat(\"\\n\")\n    print(knitr::kable(table_list[[i]]))\n    cat(\"\\n\")\n  }\n}"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#recall-test-data",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#recall-test-data",
    "title": "E1_Power_Analysis",
    "section": "Recall Test Data",
    "text": "Recall Test Data\n\n# obtain recall data from typed answers\n\nrecall_data &lt;- filtered_data %&gt;%\n  filter(phase %in% c(\"recall_1\",\"recall_2\") == TRUE ) %&gt;%\n  select(ID,phase,paragraph) %&gt;%\n  pivot_wider(names_from = phase,\n              values_from = paragraph) %&gt;%\n  mutate(recall_1 = paste(recall_1,recall_2,sep = \" \")) %&gt;%\n  select(ID,recall_1) %&gt;%\n # separate_longer_delim(cols = recall_1,\n #                        delim = \" \") %&gt;%\n  mutate(recall_1 = tolower(recall_1)) %&gt;%\n  mutate(recall_1 = gsub(\"[^[:alnum:][:space:]]\",\"\",recall_1))\n\nencoding_words_per_subject &lt;- filtered_data %&gt;%\n  filter(encoding_trial_type == \"study_word\",\n         phase == \"main_study\")\n\nrecall_data &lt;- left_join(encoding_words_per_subject,recall_data,by = 'ID') %&gt;%\n  mutate(recall_1 = strsplit(recall_1,\" \"))\n\n# implement a spell-checking method\n\nrecall_success &lt;- c()\nmin_string_distance &lt;- c()\nfor(i in 1:dim(recall_data)[1]){\n  recalled_words &lt;- unlist(recall_data$recall_1[i])\n  recalled_words &lt;- recalled_words[recalled_words != \"\"]\n  if (length(recalled_words) == 0 ) recalled_words &lt;- \"nonerecalled\"\n  recall_success[i] &lt;- tolower(recall_data$target_word[i]) %in% recalled_words\n  min_string_distance[i] &lt;- min(sapply(recalled_words,FUN = function(x) {\n  stringdist::stringdist(a=x,b = tolower(recall_data$target_word[i]), method = \"lv\")\n}))\n}\n\n# recall proportion correct by subject\n\nrecall_data_subject &lt;- recall_data %&gt;%\n  mutate(recall_success = recall_success,\n         min_string_distance = min_string_distance) %&gt;%\n  mutate(close_recall = min_string_distance &lt;= 2) %&gt;%\n  group_by(ID,study_instruction,encoding_recall,block_type) %&gt;%\n  summarise(number_recalled = sum(recall_success),\n            number_close_recalled = sum(close_recall)) %&gt;%\n  ungroup() %&gt;%\n  mutate(proportion_recalled = case_when(encoding_recall == \"no_recall\" ~ number_close_recalled/6,\n                                         encoding_recall == \"recall\" ~ number_close_recalled/6)) %&gt;%\n  mutate(ID = as.factor(ID),\n         study_instruction = as.factor(study_instruction),\n         encoding_recall = as.factor(encoding_recall),\n         block_type = as.factor(block_type))\n\n# power analysis parameters from empirical data\nmean_p_recall_per_cell &lt;- mean(recall_data_subject$proportion_recalled)\nsd_p_recall_per_cell &lt;- sd(recall_data_subject$proportion_recalled)\nemp_dist_p_recall_per_cell &lt;- recall_data_subject$proportion_recalled"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#power-analysis",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#power-analysis",
    "title": "E1_Power_Analysis",
    "section": "Power-analysis",
    "text": "Power-analysis\nVery simple approach. Use the mean_p_recall_per_cell to generate data from a binomial distribution.\n6 observations per cell (comparison between cells, simple effects)\n\n# This number came from empirical data\nmean_p_recall_per_cell &lt;- .2\n\n# create a tibble to store simulation results\nsim_data &lt;- tibble()\n\n# simulation parameters\nnum_sims &lt;- 200 # number of times to a run a simulated experiment\nnumber_of_subs &lt;- c(10,20,30,40,50,60,70,80,90,100,150,200)\neffect_sizes &lt;- c(.01,.02,.03,.04,.05,.1,.2)\n\n\n# Loop to run all simulations for every parameter\nfor(n in number_of_subs) {\n  print(n) # shows simulation progress in the console\n  \n  for (effect in effect_sizes) {\n    p_vals &lt;-\n      rep(0, num_sims) # initialize variable to store p values from each experiment\n    \n    # run simulated experiments\n    for (reps in 1:num_sims) {\n      # A uses rbinom to simulated how many words a person remembers given the base probability\n      A &lt;-\n        colMeans(replicate(n, rbinom(6, 1, mean_p_recall_per_cell)))\n      \n      # B adds the effect size to the base probability\n      B &lt;-\n        colMeans(replicate(n, rbinom(\n          6, 1, mean_p_recall_per_cell + effect\n        )))\n      \n      # run a t-test to compare whether the two are different\n      t_test &lt;- t.test(A, B, paired = TRUE)\n      \n      # store the p-value in the vector\n      p_vals[reps] &lt;- t_test$p.value\n      \n    }\n    \n    # add the results to a tibble with one row\n    sim_result &lt;- tibble(\n      subs = n,\n      effect_size = effect,\n      rep = reps,\n      prop_p_value = length(p_vals[p_vals &lt; .05]) / num_sims # this is proportion of significant experiments, or power\n    )\n    \n    sim_data &lt;- rbind(sim_data, sim_result)\n  }\n}\n\n[1] 10\n[1] 20\n[1] 30\n[1] 40\n[1] 50\n[1] 60\n[1] 70\n[1] 80\n[1] 90\n[1] 100\n[1] 150\n[1] 200\n\n# summarize the data for plotting\nsim_data_means &lt;- sim_data %&gt;%\n  mutate(effect_size = as.factor(effect_size)) %&gt;%\n  group_by(subs,effect_size) %&gt;%\n  summarise(mean_proportion = mean(prop_p_value), .groups = 'drop')\n\n# plot the data\nggplot(sim_data_means,\n       aes(x=subs,\n           y=mean_proportion,\n           group = effect_size,\n           color = effect_size)) +\n  geom_point()+\n  geom_line()+\n  ylab(\"Proportion of significant experiments (Power)\")\n\n\n\n\n\n\n\n\n12 observations per cell: simple effects for main effect of levels of processing\n\nsim_data &lt;- tibble()\n\nnum_sims &lt;- 200\nnumber_of_subs &lt;- c(10,20,30,40,50,60,70,80,90,100,150,200)\neffect_sizes &lt;- c(.01,.02,.03,.04,.05,.1,.2)\n\nfor(n in number_of_subs){\n  print(n)\n  for(effect in effect_sizes){\n    p_vals &lt;- rep(0,num_sims)\n    for(reps in 1:num_sims){\n      \n      A &lt;- colMeans(replicate(n, rbinom(12,1,mean_p_recall_per_cell)))\n      B &lt;- colMeans(replicate(n, rbinom(12,1,mean_p_recall_per_cell+effect)))\n\n      t_test &lt;- t.test(A,B,paired = TRUE)\n      p_vals[reps] &lt;- t_test$p.value\n    }\n      \n     sim_result &lt;- tibble(subs = n, \n                           effect_size = effect,\n                           rep = reps,\n                           prop_p_value = length(p_vals[p_vals &lt; .05])/num_sims)\n      \n      sim_data &lt;- rbind(sim_data,sim_result)\n  }\n}\n\n[1] 10\n[1] 20\n[1] 30\n[1] 40\n[1] 50\n[1] 60\n[1] 70\n[1] 80\n[1] 90\n[1] 100\n[1] 150\n[1] 200\n\nsim_data_means &lt;- sim_data %&gt;%\n  mutate(effect_size = as.factor(effect_size)) %&gt;%\n  group_by(subs,effect_size) %&gt;%\n  summarise(mean_proportion = mean(prop_p_value), .groups = 'drop')\n\nggplot(sim_data_means,\n       aes(x=subs,\n           y=mean_proportion,\n           group = effect_size,\n           color = effect_size)) +\n  geom_point()+\n  geom_line()"
  },
  {
    "objectID": "vignettes/data-analysis/E1_Power_Analysis.html#save-data",
    "href": "vignettes/data-analysis/E1_Power_Analysis.html#save-data",
    "title": "E1_Power_Analysis",
    "section": "save data",
    "text": "save data\n\nsave.image(\"data/E1_Power.RData\")"
  },
  {
    "objectID": "vignettes/design/E1_design.html",
    "href": "vignettes/design/E1_design.html",
    "title": "E1 Design",
    "section": "",
    "text": "Our initial goal was to replicate the self-reference effect (Rogers, Kuiper, and Kirker 1977) using an online procedure (see also, Bentley, Greenaway, and Haslam 2017).\nOur pilot work involved obtaining a large list of adjectives for describing personal attributes (Chandler 2018), and then implementing a word-selection algorithm to create a stimulus set for a design similar to the one implemented by Rogers, Kuiper, and Kirker (1977).\nThe original Rogers study, and the 2017 replication had questions that were not balanced in terms of general task demands. Some questions involved comparison between two words, and others did not. For example, the semantic comparison question could be “Does the following word mean ‘old’? IMMATURE. Whereas an example self-reference question was”Would you use the following word to describe yourself? smug”. The semantics question presents two words on the trial, whereas the self-reference question presents only one.\nWe considered how to create balanced designs in our pilot work where every target word was presented with a comparison word. However, after further consideration, we opted to present a single target word on each trial and omitted all comparison words."
  },
  {
    "objectID": "vignettes/design/E1_design.html#general-background",
    "href": "vignettes/design/E1_design.html#general-background",
    "title": "E1 Design",
    "section": "",
    "text": "Our initial goal was to replicate the self-reference effect (Rogers, Kuiper, and Kirker 1977) using an online procedure (see also, Bentley, Greenaway, and Haslam 2017).\nOur pilot work involved obtaining a large list of adjectives for describing personal attributes (Chandler 2018), and then implementing a word-selection algorithm to create a stimulus set for a design similar to the one implemented by Rogers, Kuiper, and Kirker (1977).\nThe original Rogers study, and the 2017 replication had questions that were not balanced in terms of general task demands. Some questions involved comparison between two words, and others did not. For example, the semantic comparison question could be “Does the following word mean ‘old’? IMMATURE. Whereas an example self-reference question was”Would you use the following word to describe yourself? smug”. The semantics question presents two words on the trial, whereas the self-reference question presents only one.\nWe considered how to create balanced designs in our pilot work where every target word was presented with a comparison word. However, after further consideration, we opted to present a single target word on each trial and omitted all comparison words."
  },
  {
    "objectID": "vignettes/design/E1_design.html#theoretical-background",
    "href": "vignettes/design/E1_design.html#theoretical-background",
    "title": "E1 Design",
    "section": "Theoretical background",
    "text": "Theoretical background\nThe self-reference effect (Rogers, Kuiper, and Kirker 1977) is often explained in terms of levels of processing. On this view, the recall advantage for self-referenced items is due to “deeper” processing during encoding. For example, by thinking about how a word may or may not describe oneself, the word could be associatively connected to personal experiences forming a narrative. This process of forming meaningful connections between a word and personal experiences during initial encoding could strengthen the memory trace making it easier to recall during the test phase.\nA general theme for this project is to consider a potential role for retrieval processes in mediating the self-reference effect.\nThis experiment was designed to test a retrieval practice hypothesis. Retrieval practice occurs when a person attempts to bring a particular concept or word to mind. A practice attempt occurs when a word is successfully brought to mind. Words that have received more prior retrieval practice are assumed to be easier to bring to mind in a later recall test.\nOur hypothesis is that the self-reference condition may prompt people to engage in retrieval practice with target words. Given the prompt, “Would you use the following word to describe yourself?”, and the target word, “RESPONSIBLE”; a participant may mentally repeat the question and word as they consider their response (YES/NO). For example, one might ask, “am I responsible?”, “does responsible really describe me?”, “well, there was that one time I was responsible…”. This type of inner monologue provides retrieval practice for the target in word in question, which should enhance their recallability at test."
  },
  {
    "objectID": "vignettes/design/E1_design.html#words",
    "href": "vignettes/design/E1_design.html#words",
    "title": "E1 Design",
    "section": "Words",
    "text": "Words\nWe obtained a list of person-descriptive words from (Chandler 2018). The list of words was filtered to exclude any words containing punctuation, and words that we considered derogatory and otherwise objectionable.\n\nlibrary(dplyr)\nhandpicked &lt;- rio::import(\"handpicked_2.xlsx\")\n\n# remove words with dashes and spaces\nhandpicked &lt;- handpicked %&gt;%\n  filter(keep == 1,\n         !grepl(\" \",Word),\n         !grepl(\"-\",Word),\n         !grepl(\" \",related_same),\n         !grepl(\"-\",related_same),\n         !grepl(\" \",related_diff),\n         !grepl(\"-\",related_diff)\n         )\n\nhandpicked &lt;- handpicked %&gt;%\n  select(Word,likeable_type)\n\nrio::export(handpicked,\"large_stimlist.json\")\n\nOur stimulus set had a total of 375 words. These words were categorized as high versus low likeable (by Chandler 2018). There were 173 high likeable words, and 202 low likeable words.\n\nhandpicked &lt;- rio::import(\"large_stimlist.json\")\n\nhandpicked %&gt;%\n  group_by(likeable_type) %&gt;%\n  count()\n\n# A tibble: 2 × 2\n# Groups:   likeable_type [2]\n  likeable_type     n\n  &lt;chr&gt;         &lt;int&gt;\n1 high            173\n2 low             202"
  },
  {
    "objectID": "vignettes/design/E1_design.html#questions",
    "href": "vignettes/design/E1_design.html#questions",
    "title": "E1 Design",
    "section": "Questions",
    "text": "Questions\nOur design had three encoding questions used in prior research (Bentley, Greenaway, and Haslam 2017) to vary depth of processing during encoding.\n\nCASE: Is the following word written in upper case?\nSEMANTIC: Does the following word have a positive meaning?\nSELF: Would you use the following word to describe yourself?\n\nWe randomly chose 12 unqiue words (6 high, and 6 low likeable) for each of the three conditions (36 words in total).\nFour additional filler items were inserted at the beginnin and end of the encoding phase.\nHalf of the subjects were assigned to a blocked condition (blocked by question type), and the other half were assigned to a mixed condition (intermixed questions)"
  },
  {
    "objectID": "vignettes/design/E1_design.html#primary-manipulation",
    "href": "vignettes/design/E1_design.html#primary-manipulation",
    "title": "E1 Design",
    "section": "Primary manipulation",
    "text": "Primary manipulation\nOn each trial the question was presented for three seconds, followed by the target word. Participants were asked to response Yes or No to make a case, semantic, or self-reference judgments.\nImportantly, on half of the trials there was an immediate recall task. Participants were presented with a question to recall the immediately preceding word. As a result, participants received retrieval practice during the encoding phase for half of the words in each of the encoding conditions.\nNOTE: the above was not implemented in the design. For each set of 12 words, 4 involved immediate recall and 8 did not."
  },
  {
    "objectID": "vignettes/design/E1_design.html#design-structure",
    "href": "vignettes/design/E1_design.html#design-structure",
    "title": "E1 Design",
    "section": "Design structure",
    "text": "Design structure\nEncoding Question (Case, Semantic, Self) - within-subject Retrieval practice (Yes, No) - within-subject Question Order (blocked, mixed) - between-subject\nThe design was a 3 (Encoding Question: Case, Semantic, Self) x 2 (Retrieval Practice: Yes, No) x 2 (Question Order: Blocked, Mixed) factorial with Encoding Question, and Retrieval as within-subject factors, and Question Order as a between-subject factor."
  },
  {
    "objectID": "vignettes/design/E1_design.html#predictions",
    "href": "vignettes/design/E1_design.html#predictions",
    "title": "E1 Design",
    "section": "Predictions",
    "text": "Predictions\nIn the no retrieval practice condition we expected to replicate the standard self-reference effect. Specifically, we expected recall rates to increase with depth encoding, such that recall would be highest in the self-reference condition, and lowest in the case-judgment condition (case &lt; semantic &lt; self).\nIn the retrieval practice condition we considered two possible outcomes. First, it is possible that participants already engage in retrieval practice (by mentally repeating the word) for words in the self-reference condition; and, that they do not engage in retrieval practice for the case or semantic judgments (which can be answered immediately without mentally repeating the word). In this case, retrieval practice may improve recall for words in the case and semantic conditions compared to the self-reference condition which may already be benefitting from retrieval practice. An outcome could be improved and potentially equivalent recall in all conditions (case = semantic = self). In other words, if the self-reference condition has superior recall rates because of retrieval practice, then we expected that delivering retrieval practice for items in the case and semantic conditions would improve recallability to the level of the self-reference condition.\nAnother possibility is that retrieval practice benefits recall for all words in all conditions. Here, we might expect a main effect of retrieval practice, and no interaction with the encoding question factor."
  }
]